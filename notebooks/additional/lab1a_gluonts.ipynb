{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5541bcab-2a86-4859-bf84-971f74759f3b",
   "metadata": {},
   "source": [
    "<img width=\"30%\" src=\"https://ts.gluon.ai/dev/_static/gluonts.svg\" alt=\"GluonTS logo\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "# Lab 1A: GluonTS\n",
    "\n",
    "[GluonTS](https://ts.gluon.ai/stable/) is a Python library for probabilistic time series modeling, with a focus on deep learning-based approaches. \n",
    "\n",
    "First introduced in the [paper](https://www.jmlr.org/papers/volume21/19-820/19-820.pdf), it provides a toolkit for tasks such as forecasting and anomaly detection, simplifying the development and experimentation process for time series models. Supporting both PyTorch and MXNet implementations, GluonTS offers a modular and scalable design that is suitable for both experimentation and production use.\n",
    "\n",
    "Refer to the blog post [Creating neural time series models with Gluon Time Series](https://aws.amazon.com/blogs/machine-learning/creating-neural-time-series-models-with-gluon-time-series/) for an introduction to GluonTS.\n",
    "\n",
    "The library includes essential components like neural network architectures for sequences, feature processing steps, and [evaluation](https://ts.gluon.ai/stable/api/gluonts/gluonts.evaluation.html). It also comes with pre-built implementations of state-of-the-art [models](https://ts.gluon.ai/stable/getting_started/models.html), allowing for easy benchmarking and comparison. GluonTS supports various [data formats](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.html) and provides [data loading](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.loader.html) and iteration capabilities, making it suitable for handling large-scale time series datasets. Whether you're a scientist developing new models or a practitioner looking for out-of-the-box solutions, GluonTS offers the flexibility and tools needed to tackle complex time series problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6850f11-e931-4392-ba7c-17a012d9bd14",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fe8fe-db6a-4856-bf85-b385bde51ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downgrade sentencepiece to 0.1.99 because it causes incompatibility issues in SMD 2.0\n",
    "# this is fixed in SMD >= 2.1.0\n",
    "# %pip -q install sentencepiece==0.1.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7b450-764c-4fbe-b1c0-e0bfdd2f43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install --upgrade seaborn orjson statsmodels gluonts[mxnet] gluonts[Prophet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47ec9a-f7dc-4930-bb6e-ddac4768f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need to restart kernel to get the packages\n",
    "# import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d0333-eabd-46b3-a44a-766ddd6bab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need gluonts >= 0.15.1 otherwise DeepAR is not going to work\n",
    "%pip show gluonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666066f-ee1e-43e8-92a9-094b81c88d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "from time import gmtime, strftime, sleep\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import sagemaker\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.colors as mcolors\n",
    "from itertools import islice\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "interact, interactive, fixed, interact_manual,\n",
    "IntSlider, Checkbox, Dropdown, DatePicker, Select, SelectMultiple, Checkbox\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b33c6a-7164-4888-9770-8833d3bdc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plt environment\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 3)\n",
    "colors = list(mcolors.TABLEAU_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638e9db-2693-4e24-ab1a-360a6b23b7d0",
   "metadata": {},
   "source": [
    "## Set literals and general variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d405e2-2c48-4544-8b23-c3a7ecfb33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45aa0d4-b44a-456f-987b-5295c2ba5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sagemaker_session.default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = \"gluonts-demo-notebook\"  # prefix used for all data stored within the bucket\n",
    "experiment_prefix = \"gluonts\"\n",
    "extract_to_path = '../data'\n",
    "\n",
    "sm_role = sagemaker.get_execution_role()  # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b598b-e85e-4863-89ab-0bb82ee9e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get domain_id and user profile name\n",
    "NOTEBOOK_METADATA_FILE = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "domain_id = None\n",
    "\n",
    "if os.path.exists(NOTEBOOK_METADATA_FILE):\n",
    "    with open(NOTEBOOK_METADATA_FILE, \"rb\") as f:\n",
    "        domain_id = json.loads(f.read()).get('DomainId')\n",
    "        print(f\"SageMaker domain id: {domain_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91113d8d-d823-42ea-b1fb-3b84406fdc19",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "Download the from the SageMaker example S3 bucket. You use the [electricity dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014) from the repository of the University of California, Irvine:\n",
    "> Trindade, Artur. (2015). ElectricityLoadDiagrams20112014. UCI Machine Learning Repository. https://doi.org/10.24432/C58C86."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c51a6-99ad-4824-865c-d09e5a50bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(extract_to_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63594475-4f8d-406c-9f63-0864a56f2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_zip_file_name = 'LD2011_2014.txt.zip'\n",
    "dataset_path = f'{extract_to_path}/LD2011_2014.txt'\n",
    "\n",
    "s3_dataset_path = f\"datasets/timeseries/uci_electricity/{dataset_zip_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164fc3d-9b63-42a6-8096-627f71ff7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(dataset_path):\n",
    "    print(f'Downloading and unzipping the dataset to {dataset_path}')\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.download_file(\n",
    "        f\"sagemaker-example-files-prod-{region}\", s3_dataset_path, f\"{extract_to_path}/{dataset_zip_file_name}\"\n",
    "    )\n",
    "\n",
    "    with zipfile.ZipFile(f\"{extract_to_path}/{dataset_zip_file_name}\", \"r\") as zip_ref:\n",
    "        total_size = sum(file.file_size for file in zip_ref.infolist())\n",
    "\n",
    "        with tqdm.tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Extracting\") as pbar:\n",
    "            for file in zip_ref.infolist():\n",
    "                zip_ref.extract(file, extract_to_path)\n",
    "                pbar.update(file.file_size)\n",
    "        \n",
    "    dataset_path = '.'.join(zip_ref.filename.split('.')[:-1])\n",
    "else:\n",
    "    print(f'The dataset {dataset_path} exists, skipping download and unzip!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7635bc8-2ba6-42b1-98b1-2d1f3496fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what is inside the file\n",
    "# !head -n 2 {dataset_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c4481-c1f3-4552-8b40-d7e50ddab20c",
   "metadata": {},
   "source": [
    "## Explore and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5389e-f538-43fe-b98a-10b1897cd3c3",
   "metadata": {},
   "source": [
    "### Load into a DataFrame and resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62527508-3afc-435f-be75-4cc44997ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\n",
    "    dataset_path, \n",
    "    sep=';', \n",
    "    index_col=0,\n",
    "    decimal=',',\n",
    "    parse_dates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd85b50-dcf7-4fae-9b30-055ecaf09708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a44285-c79f-4536-826d-4483a82acfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to 1h intervals\n",
    "freq = \"1h\"\n",
    "div = 4 # 1 hour contain 4x 15 min intervals, you need to  delete the resampled value by 4\n",
    "num_timeseries = df_raw.shape[1]\n",
    "data_kw = df_raw.resample(freq).sum() / div\n",
    "timeseries = []\n",
    "\n",
    "for i in tqdm.trange(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data_kw.iloc[:, i], trim=\"f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8cfdc7-1170-4596-9e25-c2a973c3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75072d3a-0075-4745-83e2-1f7cab2bc78e",
   "metadata": {},
   "source": [
    "### Visualize time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ac1f0-4a51-4ccf-b758-5c7b633ac0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(timeseries, start_time, length):\n",
    "    n_cols = 2\n",
    "    n_rows = (len(timeseries) + 1)//2\n",
    "    \n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 4*n_rows), sharex=True)\n",
    "    axx = axs.ravel()\n",
    "    for i, ts in tqdm.tqdm(enumerate(timeseries), total=len(timeseries), desc=\"Creating plots\"):\n",
    "        series = ts.loc[start_time:start_time + length*ts.index.freq]\n",
    "        if len(series): series.plot(ax=axx[i])\n",
    "\n",
    "        axx[i].set_xlabel(\"date\")\n",
    "        axx[i].set_ylabel(f\"kW consumption - {ts.name} - {ts.index.freq}\")\n",
    "        axx[i].grid(which=\"minor\", axis=\"x\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1ff47-53d5-49e8-b456-e81b98ff0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "ts_id_list = [ts.name for ts in timeseries]\n",
    "show_start_date = pd.Timestamp(\"2014-12-01\")\n",
    "time_step = timeseries[0].index.freq\n",
    "max_samples = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7aa43-168a-4eae-847e-1bfbf62a854b",
   "metadata": {},
   "source": [
    "Use the interactive plotting to visualize time series. You can change the following parameters:\n",
    "- `Time series ids`: ids of the time series in the full dataset. You can select multiple time series to predict and to plot\n",
    "- `Show from`: start of the displayed interval  \n",
    "- `Length`: how many time steps are displayed starting from `Show from`\n",
    "- `Random samples` and `Number of samples`: use these controls to show a random sample of the specified size from the time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac7510-0d0e-4dd5-a224-57460c4343b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    ts_ids=SelectMultiple(options=ts_id_list, value=[ts_id_list[0]], rows=5, style=style, description='Time series ids:'),\n",
    "    start_date=DatePicker(value=show_start_date, style=style, description='Show from:'),\n",
    "    length=IntSlider(min=1, max=730, value=100, style=style, description=f'Length in {time_step}:'),\n",
    "    random_samples=Checkbox(value=False, description='Random samples'),\n",
    "    num_samples=IntSlider(min=1, max=min(max_samples, len(ts_id_list)), value=min(10,len(ts_id_list)), style=style, description='Number of samples:'),\n",
    "    continuous_update=False,\n",
    ")\n",
    "def plot_interact(ts_ids, start_date, length, random_samples, num_samples):\n",
    "    ids = random.sample(ts_id_list, num_samples) if random_samples else ts_ids\n",
    "    plot_timeseries([ts for ts in timeseries if ts.name in ids], start_date, length)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a89b7d-4b83-4803-8204-85e6755cd6b4",
   "metadata": {},
   "source": [
    "### Optional: analyse time series\n",
    "In this section you analyse time series by performing common operations like auto correlation analysis, stationarity detection, trend and seasonality period calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba75fd-b93c-40e9-9e42-c2ba5ad2a4fa",
   "metadata": {},
   "source": [
    "More specifically, the following code does:\n",
    "\n",
    "**Basic statistics:**\n",
    "- Mean, median, standard deviation\n",
    "- Skewness and kurtosis\n",
    "- Missing value detection\n",
    "- Data frequency and span\n",
    "  \n",
    "**Stationarity analysis:**\n",
    "- Augmented Dickey-Fuller test\n",
    "- KPSS test\n",
    "- Rolling statistics\n",
    "  \n",
    "**Distribution analysis:**\n",
    "- Normality tests\n",
    "- Quantile analysis\n",
    "- Histogram generation\n",
    "\n",
    "**Changepoint detection:**\n",
    "- Moving average based detection\n",
    "\n",
    "**Outlier detection:**\n",
    "- Z-score method\n",
    "- IQR method\n",
    "\n",
    "**Correlation analysis:**\n",
    "- ACF (Autocorrelation Function)\n",
    "- PACF (Partial Autocorrelation Function)\n",
    "- Significant lag identification\n",
    "  \n",
    "**Cyclical pattern analysis:**\n",
    "- Spectral analysis using FFT\n",
    "- Dominant frequency identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d403e2-615d-4b64-954a-7a757799e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesAnalyzer:\n",
    "    \"\"\"\n",
    "    Basic time series analysis example\n",
    "    \"\"\"\n",
    "    def __init__(self, series, freq='H', title=None):\n",
    "        self.series = series\n",
    "        self.freq = freq\n",
    "        self.title = title or f'Analysis for time series {series.name}'\n",
    "        self.results = {}\n",
    "        self.expected_periods = { # Set analysis periods based on frequency\n",
    "            'H': [24, 168, 730],  # daily, weekly, monthly\n",
    "            'D': [7, 30, 365],    # weekly, monthly, yearly\n",
    "            'M': [12]             # yearly\n",
    "        }[self.freq]\n",
    "        \n",
    "    def run_full_analysis(self):\n",
    "        \"\"\"\n",
    "        Run all available analyses.\n",
    "        \"\"\"\n",
    "        self.results = {\n",
    "            'basic_stats': self.calculate_basic_stats(),\n",
    "            'stationarity': self.check_stationarity(),\n",
    "            'seasonality': self.analyze_seasonality(),\n",
    "            'distribution': self.analyze_distribution(),\n",
    "            'changepoints': self.detect_changepoints(),\n",
    "            'outliers': self.detect_outliers(),\n",
    "            'cyclical': self.analyze_cyclical_patterns(),\n",
    "            'autocorrelation': self.analyze_autocorrelation()\n",
    "        }\n",
    "        return self.results\n",
    "    \n",
    "    def calculate_basic_stats(self):\n",
    "        \"\"\"\n",
    "        Calculate basic time series statistics.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'mean': self.series.mean(),\n",
    "            'median': self.series.median(),\n",
    "            'std': self.series.std(),\n",
    "            'skewness': self.series.skew(),\n",
    "            'kurtosis': self.series.kurtosis(),\n",
    "            'missing_values': self.series.isnull().sum(),\n",
    "            'length': len(self.series),\n",
    "            'start_date': self.series.index.min(),\n",
    "            'end_date': self.series.index.max(),\n",
    "            'frequency': self.freq\n",
    "        }\n",
    "    \n",
    "    def check_stationarity(self):\n",
    "        \"\"\"\n",
    "        Perform stationarity analysis.\n",
    "        \"\"\"\n",
    "        # ADF Test\n",
    "        adf_result = adfuller(self.series.dropna())\n",
    "        \n",
    "        # KPSS Test\n",
    "        kpss_result = kpss(self.series.dropna())\n",
    "        \n",
    "        # Calculate rolling statistics\n",
    "        rolling_mean = self.series.rolling(window=self.expected_periods[0]).mean()\n",
    "        rolling_std = self.series.rolling(window=self.expected_periods[0]).std()\n",
    "        \n",
    "        return {\n",
    "            'adf_test': {\n",
    "                'statistic': adf_result[0],\n",
    "                'p_value': adf_result[1],\n",
    "                'critical_values': adf_result[4],\n",
    "                'is_stationary': adf_result[1] < 0.05\n",
    "            },\n",
    "            'kpss_test': {\n",
    "                'statistic': kpss_result[0],\n",
    "                'p_value': kpss_result[1],\n",
    "                'is_stationary': kpss_result[1] > 0.05\n",
    "            },\n",
    "            'rolling_statistics': {\n",
    "                'mean': rolling_mean,\n",
    "                'std': rolling_std\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_seasonality(self):\n",
    "        \"\"\"\n",
    "        Analyze seasonal patterns using multiple methods.\n",
    "        \"\"\"\n",
    "        # Perform seasonal decomposition for each expected period\n",
    "        decompositions = {}\n",
    "        for period in self.expected_periods:\n",
    "            try:\n",
    "                decomp = seasonal_decompose(self.series, period=period)\n",
    "                strength = np.var(decomp.seasonal) / np.var(decomp.resid + decomp.seasonal)\n",
    "                decompositions[period] = {\n",
    "                    'decomposition': decomp,\n",
    "                    'strength': strength\n",
    "                }\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'decompositions': decompositions\n",
    "        }\n",
    "    \n",
    "    def analyze_distribution(self):\n",
    "        \"\"\"\n",
    "        Analyze the distribution of the time series.\n",
    "        \"\"\"\n",
    "        # Normality test\n",
    "        _, normality_p_value = normaltest(self.series.dropna())\n",
    "        \n",
    "        # Calculate quantiles\n",
    "        quantiles = self.series.quantile([0.25, 0.5, 0.75])\n",
    "        \n",
    "        return {\n",
    "            'normality_test': {\n",
    "                'p_value': normality_p_value,\n",
    "                'is_normal': normality_p_value > 0.05\n",
    "            },\n",
    "            'quantiles': quantiles,\n",
    "            'iqr': quantiles[0.75] - quantiles[0.25],\n",
    "            'histogram_data': np.histogram(self.series, bins='auto')\n",
    "        }\n",
    "        \n",
    "    def detect_changepoints(self):\n",
    "        \"\"\"\n",
    "        Detect significant changes in the time series.\n",
    "        \"\"\"\n",
    "        # Simple moving average difference\n",
    "        ma = self.series.rolling(window=self.expected_periods[0]).mean()\n",
    "        diff = ma.diff()\n",
    "        \n",
    "        # Detect points where difference exceeds 2 standard deviations\n",
    "        threshold = 2 * diff.std()\n",
    "        changepoints = self.series.index[abs(diff) > threshold]\n",
    "        \n",
    "        return {\n",
    "            'changepoints': changepoints,\n",
    "            'n_changepoints': len(changepoints),\n",
    "            'threshold': threshold\n",
    "        }\n",
    "    \n",
    "    def detect_outliers(self):\n",
    "        \"\"\"\n",
    "        Detect outliers using multiple methods.\n",
    "        \"\"\"\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(self.series.dropna()))\n",
    "        z_score_outliers = self.series.index[z_scores > 3]\n",
    "        \n",
    "        # IQR method\n",
    "        Q1 = self.series.quantile(0.25)\n",
    "        Q3 = self.series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        iqr_outliers = self.series.index[\n",
    "            (self.series < (Q1 - 1.5 * IQR)) | \n",
    "            (self.series > (Q3 + 1.5 * IQR))\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            'z_score': {\n",
    "                'outliers': z_score_outliers,\n",
    "                'count': len(z_score_outliers)\n",
    "            },\n",
    "            'iqr': {\n",
    "                'outliers': iqr_outliers,\n",
    "                'count': len(iqr_outliers)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def analyze_cyclical_patterns(self):\n",
    "        \"\"\"\n",
    "        Analyze cyclical patterns using spectral analysis.\n",
    "        \"\"\"\n",
    "        # Perform FFT\n",
    "        fft_values = np.fft.fft(self.series.dropna().values)\n",
    "        fft_freq = np.fft.fftfreq(len(self.series))\n",
    "        \n",
    "        # Find dominant frequencies\n",
    "        dominant_idx = np.argsort(np.abs(fft_values))[-5:]  # Top 5 frequencies\n",
    "        \n",
    "        return {\n",
    "            'dominant_frequencies': fft_freq[dominant_idx],\n",
    "            'dominant_amplitudes': np.abs(fft_values)[dominant_idx]\n",
    "        }\n",
    "    \n",
    "    def analyze_autocorrelation(self):\n",
    "        \"\"\"\n",
    "        Analyze autocorrelation and partial autocorrelation.\n",
    "        \"\"\"\n",
    "        nlags = min(self.expected_periods[-1], len(self.series) // 4)\n",
    "        acf_values = acf(self.series.dropna(), nlags=nlags)\n",
    "        pacf_values = pacf(self.series.dropna(), nlags=nlags)\n",
    "        \n",
    "        return {\n",
    "            'acf': acf_values,\n",
    "            'pacf': pacf_values,\n",
    "            'nlags': nlags,\n",
    "            'significant_lags': {\n",
    "                'acf': np.where(np.abs(acf_values) > 1.96/np.sqrt(len(self.series)))[0],\n",
    "                'pacf': np.where(np.abs(pacf_values) > 1.96/np.sqrt(len(self.series)))[0]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def plot_full_analysis(self):\n",
    "        \"\"\"\n",
    "        Create comprehensive visualization of all analyses.\n",
    "        \"\"\"\n",
    "        # Calculate number of seasonal decomposition subplots needed\n",
    "        n_periods = len(self.results['seasonality']['decompositions'])\n",
    "        total_plots = 5 + (n_periods * 3)  # Original + distribution + ACF/PACF + autocorrelation + frequences + (3 plots per period)\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 5 * total_plots))\n",
    "        plot_position = 1\n",
    "        \n",
    "        # 1. Original Series + Rolling Statistics\n",
    "        plt.subplot(total_plots, 1, plot_position)\n",
    "        self.series.plot(label='Original')\n",
    "        self.results['stationarity']['rolling_statistics']['mean'].plot(label=f'Rolling Mean, window={self.expected_periods[0]}')\n",
    "        self.results['stationarity']['rolling_statistics']['std'].plot(label=f'Rolling Std, window={self.expected_periods[0]}')\n",
    "        plt.title(f'{self.title} - Original Series and Rolling Statistics')\n",
    "        plt.legend()\n",
    "        plot_position += 1\n",
    "        \n",
    "        # 2. Seasonal Decompositions for each period        \n",
    "        for period, decomp_info in self.results['seasonality']['decompositions'].items():\n",
    "            period_str = str(period)\n",
    "            period_name = {'24': 'daily', '168': 'weekly', '730': 'monthly'}.get(period_str, f'{period}-hour')\n",
    "            title_suffix = f\" (Period: {period}, Strength: {decomp_info['strength']:.3f})\"\n",
    "            \n",
    "            decomp = decomp_info['decomposition']\n",
    "                        \n",
    "            # Trend\n",
    "            plt.subplot(total_plots, 1, plot_position)\n",
    "            decomp.trend.plot()\n",
    "            plt.title(f'Trend Component - {period_name.capitalize()}{title_suffix}')\n",
    "            plot_position += 1\n",
    "            \n",
    "            # Seasonal\n",
    "            plt.subplot(total_plots, 1, plot_position)\n",
    "            decomp.seasonal.plot()\n",
    "            plt.title(f'Seasonal Component - {period_name.capitalize()}{title_suffix}')\n",
    "            plot_position += 1\n",
    "            \n",
    "            # Residual\n",
    "            plt.subplot(total_plots, 1, plot_position)\n",
    "            decomp.resid.plot()\n",
    "            plt.title(f'Residual Component - {period_name.capitalize()}{title_suffix}')\n",
    "            plot_position += 1\n",
    "        \n",
    "        # 3. Distribution Analysis\n",
    "        plt.subplot(total_plots, 1, plot_position)\n",
    "        self.series.hist(bins=256)\n",
    "        plt.title('Target distribution')\n",
    "        plot_position += 1\n",
    "        \n",
    "        # 4. ACF/PACF\n",
    "        plt.subplot(total_plots, 1, plot_position)\n",
    "        corr_results = self.results['autocorrelation']\n",
    "        plt.plot(corr_results['acf'], label='ACF')\n",
    "        plt.plot(corr_results['pacf'], label='PACF')\n",
    "        plt.axhline(y=0, color='r', linestyle='-')\n",
    "        plt.axhline(y=1.96/np.sqrt(len(self.series)), color='r', linestyle='--')\n",
    "        plt.axhline(y=-1.96/np.sqrt(len(self.series)), color='r', linestyle='--')\n",
    "        plt.title('ACF/PACF')\n",
    "        plt.legend()\n",
    "        plot_position += 1\n",
    "        \n",
    "        # 5. Autocorrelation by Lag Plot\n",
    "        plt.subplot(total_plots, 1, plot_position)\n",
    "        max_lags = self.results['autocorrelation']['nlags']\n",
    "        lags = range(1, max_lags + 1)\n",
    "        correlations = [self.series.autocorr(lag=lag) for lag in lags]\n",
    "        plt.bar(lags, correlations, alpha=0.5, color='blue')\n",
    "        plt.axhline(y=0, color='r', linestyle='-')\n",
    "        plt.axhline(y=1.96/np.sqrt(len(self.series)), color='r', linestyle='--', label='95% Confidence Interval')\n",
    "        plt.axhline(y=-1.96/np.sqrt(len(self.series)), color='r', linestyle='--')\n",
    "        plt.xlabel('Lag')\n",
    "        plt.ylabel('Autocorrelation')\n",
    "        plt.title(f'Autocorrelation by lag, max lag = {max_lags}')\n",
    "        plt.legend()\n",
    "        plot_position += 1\n",
    "\n",
    "        # 6. Dominant Frequencies Plot\n",
    "        ax = plt.subplot(total_plots, 1, plot_position)\n",
    "        cyclical_results = self.results['cyclical']\n",
    "        freq = cyclical_results['dominant_frequencies']\n",
    "        \n",
    "        ax.stem(cyclical_results['dominant_frequencies'], cyclical_results['dominant_amplitudes'])\n",
    "        ax.set_xlim([np.min(freq)*2, np.max(freq)*2])\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('Dominant Frequencies')\n",
    "        plt.legend()\n",
    "        plot_position += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770de02c-ddad-4c14-89aa-7d9577b11c9a",
   "metadata": {},
   "source": [
    "Use the interactive plotting to analyse a specific time series. You can change the following parameters:\n",
    "- `Time series id`: id of the time series in the full dataset\n",
    "- `Analyse from` and `Analyse to`: start and end of the analysed interval  \n",
    "- `Random sample`: activate this to pick a random sample from the full time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ffdfa-7891-47ff-a0b7-b902f881b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "ts_id_list = [ts.name for ts in timeseries]\n",
    "analyse_start_date = pd.Timestamp(\"2014-01-01\")\n",
    "analyse_end_date = pd.Timestamp(\"2014-04-30\")\n",
    "time_step = timeseries[0].index.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c372d-3d6e-45cd-bfa5-72fcdfed4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    ts_ids=Select(options=ts_id_list, value=ts_id_list[0], rows=5, style=style, description='Time series id:'),\n",
    "    start_date=DatePicker(value=analyse_start_date, style=style, description='Analyse from:'),\n",
    "    end_date=DatePicker(value=analyse_end_date, style=style, description='Analyse to:'),\n",
    "    random_sample=Checkbox(value=False, description='Random sample'),\n",
    "    continuous_update=False,\n",
    ")\n",
    "def plot_interact(ts_ids, start_date, end_date, random_sample):\n",
    "    ids = random.sample(ts_id_list, 1) if random_sample else [ts_ids]\n",
    "    ts = [ts for ts in timeseries if ts.name in ids][0].loc[start_date:end_date]\n",
    "    \n",
    "    print(f\"Analysing time series {ts.name}, length = {len(ts)} data points...\")\n",
    "    \n",
    "    analyzer = TimeSeriesAnalyzer(ts, freq='H')\n",
    "    results = analyzer.run_full_analysis()\n",
    "    fig = analyzer.plot_full_analysis()\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # Print key findings\n",
    "    print(\"\\nKey findings:\")\n",
    "    print(f\"1. Stationarity: {'Stationary' if results['stationarity']['adf_test']['is_stationary'] else 'Non-stationary'}\")\n",
    "    print(f\"2. Distribution: {'Normal' if results['distribution']['normality_test']['is_normal'] else 'Non-normal'}\")\n",
    "    print(f\"3. Number of outliers: {results['outliers']['z_score']['count']} (z-score method)\")\n",
    "    print(f\"4. Number of changepoints: {results['changepoints']['n_changepoints']}\")\n",
    "\n",
    "    # Print more data\n",
    "    print(f\"\\nBasic statistics:\\n{pd.DataFrame.from_dict(results['basic_stats'], orient='index', columns=['value'])}\")\n",
    "    print(f\"\\nSeasonality:\\n{results['seasonality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e55ec-6106-4406-917a-a794ff11570a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61753438-dd4d-492f-8f1d-ae487c16008f",
   "metadata": {},
   "source": [
    "## Train GluonTS models: a foundational walkthrough\n",
    "In this section you begin with training and forecasting by using two simple models, [Seasonal Naive](https://otexts.com/fpp2/simple-methods.html#seasonal-na%C3%AFve-method) and [simple feedforward MLP](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/simple_feedforward/_estimator.py) to learn the foundation of GluonTS framework and get hands-on experience with GluonTS classes and utilities. You use a sample dataset with the single time series to make the example simple. \n",
    "\n",
    "After this step-by-step introduction, you move to training of more advanced models like Transformers, СNN, and [N-BEATS](https://openreview.net/forum?id=r1ecqn4YwB). Finally, you calculate and save model performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32d1fa-529d-4e91-a7cc-7c18c40a1be2",
   "metadata": {},
   "source": [
    "### Setup environment and load packages\n",
    "\n",
    "This notebook doesn't install GPU version of MXNet and uses CPU for model training and inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4f48e-bc18-461c-92b5-197ac2385a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26caeba7-831c-4791-8953-72abeef42084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import npx\n",
    "# npx.set_np()\n",
    "num_gpus = npx.num_gpus()  # Returns the number of available GPUs\n",
    "print(f\"Number of GPUs available: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812f5fb-4a1b-4089-92be-60e20751bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GluonTS modules\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split, OffsetSplitter, DateSplitter\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.jsonl import JsonLinesFile\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.model.predictor import Predictor\n",
    "from gluonts.model.forecast import QuantileForecast\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from pathlib import Path\n",
    "from gluonts.mx import Trainer\n",
    "from gluonts.mx import (\n",
    "NBEATSEnsembleEstimator, NBEATSEstimator, GaussianProcessEstimator, DeepAREstimator,\n",
    "TemporalFusionTransformerEstimator, MQCNNEstimator, MQRNNEstimator\n",
    ")\n",
    "from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n",
    "from gluonts.ext.prophet import ProphetPredictor\n",
    "from gluonts.model.npts import NPTSPredictor\n",
    "from gluonts.mx import SimpleFeedForwardEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be5f52-2fd7-4c34-8b9b-5849cb1028fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for 7 days\n",
    "prediction_days = 7\n",
    "intervals_per_day = 24\n",
    "prediction_length = prediction_days * intervals_per_day\n",
    "\n",
    "print(f\"Sampling frequency set to {freq}. Generate predictions for {prediction_length} intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78b0a7-8a25-4a89-83aa-5f90c1be82c5",
   "metadata": {},
   "source": [
    "### GluonTS built-in datasets\n",
    "GluonTS comes with many publicly available datasets. This section briefly shows what datasets are provided with GluonTS and loads the electricity dataset.\n",
    "This notebook doesn't use any built-in GluonTS dataset but you can experiment with some popular datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3b9d5-f071-45ca-924f-5be89babb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6288ec-1bbb-4d44-9592-06be830a1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Available datasets: {dataset_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a35ae-8751-46a5-b313-50500bb3a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the electicity dataset\n",
    "gluonts_dataset = get_dataset('electricity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c009f0-90cb-495a-a28c-b120da8c68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The electricity dataset contains {len(gluonts_dataset.train)} time series.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8f4b1-f5f3-46de-86fc-3bcc428acc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first time series\n",
    "entry = next(iter(gluonts_dataset.train))\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8ca83-571c-40f5-9b01-003c4b9ee6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some random time series\n",
    "for e in np.random.choice(list(gluonts_dataset.train), size=4, replace=False):\n",
    "    to_pandas(e)[-10*gluonts_dataset.metadata.prediction_length:].plot(title=f\"item id:{e[FieldName.ITEM_ID]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5b0ad-aaec-45d7-9f2e-40a8eba11bed",
   "metadata": {},
   "source": [
    "### Create a sample dataset\n",
    "\n",
    "The rest of the notebook continues to use the initially loaded original electricity dataset.\n",
    "\n",
    "Create a smaller dataset with a subset of time series. You can use this sample dataset to simplify examples and to decrease model training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8477e-f2e5-4f7e-a106-ea1103f9e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1\n",
    "MAX_TS_TO_DISPLAY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fbc3c-55fb-404b-8c85-f744a7bd086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some random time series to include in a small dataset\n",
    "sample_size = SAMPLE_SIZE\n",
    "columns_to_keep = np.random.choice(data_kw.columns.to_list(), size=sample_size, replace=False)\n",
    "columns_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9ca5f-68fd-4aac-a4ad-8255a5dc6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kw_sample = data_kw[columns_to_keep]\n",
    "data_kw_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df20a45-c117-4171-8323-9c2b2fa239d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_kw_sample.shape[1] > MAX_TS_TO_DISPLAY:\n",
    "    print(f\"\\033[91mToo many time series in the dataset to visualize, displaying a random sample of {MAX_TS_TO_DISPLAY}.\\033[0m\")\n",
    "    sample = data_kw_sample.sample(n=MAX_TS_TO_DISPLAY, axis=1)\n",
    "else:\n",
    "    sample = data_kw_sample\n",
    "    \n",
    "plot_timeseries(\n",
    "    [np.trim_zeros(sample.iloc[:, i], trim=\"f\") for i in range(sample.shape[1])],\n",
    "    pd.Timestamp(\"2014-12-01\"), intervals_per_day*14\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761e348-91f5-40fa-a20d-6ef72f10902a",
   "metadata": {},
   "source": [
    "### Convert data to GluonTS format\n",
    "A dataset should satisfy minimum requirements to be compartible with GluonTS: it should be an interable collections of data entries/time series, each entry should have at least a `target` field with values of the time series, and a `start` field with the start date of the time series.\n",
    "\n",
    "To work directly on `pandas.DataFrame` or `pandas.Series`, you can use GluonTS `PandasDataset` class. GluonTS also supports multiple time series – they can be a list of the DataFrames, a dict of DataFrames, or a long format DataFrame with `item_id` column that designates each individual time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d53ea6-6ed8-4150-8b99-792a723fcb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the last year of data for a sample\n",
    "start_training_date = pd.Timestamp('2014-01-01')\n",
    "end_dataset_date = pd.Timestamp('2014-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f1e16-29cc-4fe7-81ce-1e2296514925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = data_kw_sample[(data_kw_sample.index > start_training_date) & (data_kw_sample.index <= end_dataset_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d21b5f-793d-4de2-bfb1-d6c390022649",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset = PandasDataset(dict(df_wide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8151a0a-3fe4-4a21-a83f-832acb3da3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf7db5-61b2-4eec-af49-f790ddbe484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what is inside the PandasDataset\n",
    "entry = next(iter(ts_dataset))\n",
    "\n",
    "print(entry)\n",
    "print(f\"Number of data points: {len(entry[FieldName.TARGET])}\")\n",
    "print(f\"Number of time series in the dataset: {len(ts_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc842bd-ee4a-4de5-bbd0-a3115579a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show time series\n",
    "for i, entry in enumerate(islice(ts_dataset, MAX_TS_TO_DISPLAY)):\n",
    "    to_pandas(entry).plot(label=entry[FieldName.ITEM_ID], color=colors[i % len(colors)]) \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e50a2-0ae2-45f1-aa84-ee7adda3ef66",
   "metadata": {},
   "source": [
    "### Split into train and test datasets\n",
    "Before training, you need to split the dataset to training and test parts. You can use a built-in [`splitter`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html) to implement different strategies to split a given dataset. You can use [`OffsetSplitter`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html#gluonts.dataset.split.OffsetSplitter) to split a uniform dataset by time step offset or [`DateSplitter`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html#gluonts.dataset.split.DateSplitter) to split based on a specific date.\n",
    "\n",
    "To generate and handle test pairs containing the test input and ground truth data, you can use [`TestTemplate`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html#gluonts.dataset.split.TestTemplate) helper class.\n",
    "\n",
    "Refer to the GluonTS API documentation for [`gluonts.dataset.split`](https://ts.gluon.ai/stable/api/gluonts/gluonts.dataset.split.html#) module for other helpful constructs and utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9f925-7a8b-4699-b566-41dd0a521bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some visualization helpers\n",
    "def highlight_entry(entry, color, ax):\n",
    "    start = entry[\"start\"]\n",
    "    end = entry[\"start\"] + len(entry[\"target\"])\n",
    "    ax.axvspan(start, end, facecolor=color, alpha=0.2)\n",
    "\n",
    "def plot_dataset_splitting(\n",
    "    original_dataset, \n",
    "    training_dataset, \n",
    "    test_pairs\n",
    "):\n",
    "    n_rows = min(len(original_dataset), MAX_TS_TO_DISPLAY) + min(len(test_pairs), 2*MAX_TS_TO_DISPLAY)\n",
    "    fig, axes = plt.subplots(n_rows, 1, figsize=(15, 3*n_rows))\n",
    "    axes = axes.flatten()  # Convert 2D array of axes to 1D for easier indexing\n",
    "\n",
    "    if len(original_dataset) > MAX_TS_TO_DISPLAY or len(test_pairs) > 2*MAX_TS_TO_DISPLAY:\n",
    "        print(f\"\\033[91mToo many time series in the dataset to visualize, displaying first {MAX_TS_TO_DISPLAY} time series.\\033[0m\")\n",
    "\n",
    "    # Current subplot index\n",
    "    current_ax = 0\n",
    "    \n",
    "    # Plot original dataset and highlight the training part\n",
    "    for original_entry, train_entry in zip(islice(original_dataset, MAX_TS_TO_DISPLAY), islice(training_dataset, MAX_TS_TO_DISPLAY)):\n",
    "        ax = axes[current_ax]\n",
    "        start = original_entry[FieldName.START].to_timestamp()\n",
    "        end = (original_entry[FieldName.START] + len(original_entry[FieldName.TARGET])).to_timestamp()\n",
    "        to_pandas(original_entry).plot(ax=ax)\n",
    "        highlight_entry(train_entry, \"red\", ax)\n",
    "        ax.legend([f\"original dataset: {train_entry[FieldName.ITEM_ID]}\", \"training dataset\"], loc=\"upper left\")\n",
    "        current_ax += 1\n",
    "\n",
    "    # Plot test pairs\n",
    "    for test_input, test_label in islice(test_pairs, 2*MAX_TS_TO_DISPLAY):\n",
    "        ax = axes[current_ax]\n",
    "        to_pandas(test_input).plot(ax=ax)\n",
    "        to_pandas(test_label).plot(ax=ax)\n",
    "        highlight_entry(test_input, \"green\", ax)\n",
    "        highlight_entry(test_label, \"blue\", ax)\n",
    "        ax.set_xlim(start, end)\n",
    "        ax.legend([f\"test input: {test_input[FieldName.ITEM_ID]}\", \"test label\", \"input\", \"label\"], loc=\"upper left\")\n",
    "        current_ax += 1\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec43020-8b0f-4ae4-8c5d-15e45769a07b",
   "metadata": {},
   "source": [
    "#### Example 1: split by offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93647c04-b529-4258-8c11-6cdf8207f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by offset\n",
    "NUM_WINDOWS = 2 # you define how many test windows should be generated for each time series\n",
    "\n",
    "train_ds, test_template = OffsetSplitter(offset=-NUM_WINDOWS*prediction_length).split(ts_dataset)\n",
    "test_pairs = test_template.generate_instances(\n",
    "    prediction_length=prediction_length, \n",
    "    windows=NUM_WINDOWS, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a9f03-afbb-4bb6-966e-7f4b90d293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset is splitted in {len(train_ds)} training datasets and {len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0453a0-015f-4eb3-ae2c-6134d9fbb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "plot_dataset_splitting(ts_dataset, train_ds, test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4b784-a5b6-4ee6-858b-a1e934bb4dfe",
   "metadata": {},
   "source": [
    "#### Example 2: split by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944d04e-f093-4e5e-ae52-0b253f81c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by date\n",
    "NUM_WINDOWS = 4\n",
    "end_training_date = pd.Period(end_dataset_date, freq=freq) - NUM_WINDOWS*prediction_length\n",
    "\n",
    "train_ds, test_template = DateSplitter(date=end_training_date).split(ts_dataset)\n",
    "test_pairs = test_template.generate_instances(\n",
    "    prediction_length=prediction_length,\n",
    "    windows=NUM_WINDOWS,\n",
    "    distance=prediction_length//2, # using 'distance' argument you can make windows overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e1941-ec4d-4f58-9898-398844da8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset is splitted in {len(train_ds)} training datasets and {len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f3b5a-2552-4d06-8fab-12d34d19f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_splitting(ts_dataset, train_ds, test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b7012-d532-48d8-ba55-18b414dc5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize only ground truth (label) for each testing window\n",
    "for _, test_label in islice(test_pairs, MAX_TS_TO_DISPLAY):\n",
    "    to_pandas(test_label).plot()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973bd007-2d57-45d5-9bf2-f2a34e56a6b9",
   "metadata": {},
   "source": [
    "### Training a built-in GluonTS algorithm\n",
    "This section uses a single sample time series to demonstrate the prosess of training a model, producing predictions, and evaluating the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d5e14-cc9c-47de-a319-47590beaa863",
   "metadata": {},
   "source": [
    "To encapsulate models and trained model artifacts, GluonTS uses an `Estimator`/`Predictor` pair of abstractions that should be familiar to users of other machine learning frameworks. An `Estimator` represents a model that can be trained on a dataset to yield a `Predictor`, which can later be used to make predictions on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac36f0-a083-449f-b934-7cd54b1c212e",
   "metadata": {},
   "source": [
    "#### Example 1: Seasonal Naive\n",
    "First make prediction using a simple seasonal model.\n",
    "\n",
    "For each time series $Y$ the seasonal naive predictor produces a forecast:\n",
    "\n",
    "$\\tilde{Y}(T+k) = Y(T+k-h)$\n",
    "\n",
    "where $T$ - forecast time, $k$ - prediction length-1, $h$ - season length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46191f78-acd5-431d-a4bb-800f11ba15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset at the last two weeks of the year and predict the week before last to avoid the one-off effect of the Dec 25th\n",
    "train_ds, test_template = OffsetSplitter(offset=-2*prediction_length).split(ts_dataset)\n",
    "test_pairs = test_template.generate_instances(\n",
    "    prediction_length=prediction_length, \n",
    "    windows=1, \n",
    ")\n",
    "\n",
    "print(f\"The dataset is splitted in {len(train_ds)} training datasets and {len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1d223-0272-4421-b454-f404fca6d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of predictor\n",
    "seasonal_naive_predictor = SeasonalNaivePredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    season_length=24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62575d03-a14d-4677-8c9f-f7804d542c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "forecasts = [seasonal_naive_predictor.predict_item(test_input) for test_input, _ in test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f72e28-1fd4-4cd3-9038-0c968f13d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_entry = forecasts[0]\n",
    "\n",
    "print(f\"Number of sample paths: {forecast_entry.num_samples}\")\n",
    "print(f\"Dimension of samples: {forecast_entry.samples.shape}\")\n",
    "print(f\"Start date of the forecast window: {forecast_entry.start_date}\")\n",
    "print(f\"Frequency of the time series: {forecast_entry.freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279ed46-389d-463e-b6cb-ae4d63fde5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to predictions\n",
    "forecast_entry.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0176e9-5083-4d52-a9ca-aec125f04d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seasonal naive all quantiles are the same\n",
    "forecast_entry.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebf762-b24b-4602-9c83-6518a4216a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "i = 0\n",
    "for test_input, test_label in islice(test_pairs, MAX_TS_TO_DISPLAY):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15,3))\n",
    "\n",
    "    to_pandas(test_input)[-prediction_length:].plot(ax=ax, label=f\"Input time series: {test_input[FieldName.ITEM_ID]}\")\n",
    "    to_pandas(test_label).plot(ax=ax, label=\"Ground truth\")\n",
    "    mean_forecast = forecasts[i].to_quantile_forecast(['mean'])\n",
    "    pd.Series(data=mean_forecast.forecast_array[0], index=mean_forecast.index).plot(ax=ax, label=\"Mean forecast\")\n",
    "    i += 1\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1febec-0522-4e1d-8437-9e5af7bbb417",
   "metadata": {},
   "source": [
    "#### Evaluate predictions\n",
    "Use GluonTS [`Evaluator`](https://ts.gluon.ai/stable/api/gluonts/gluonts.evaluation.html) class to evaluate the forecast numerically. This class computes metrics per time series (item) as well as aggregated metrics accross all time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f292d3-c9a1-4260-bb30-314b4beb93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5])\n",
    "agg_metrics, item_metrics = evaluator(\n",
    "    [to_pandas(l) for l in test_pairs.label], \n",
    "    forecasts,\n",
    "    num_series=len(ts_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12cc0e-f863-4043-b668-403a68eaa89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated metrics\n",
    "print(json.dumps(agg_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d9a2d-bcf1-420a-ac97-529dec467471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics per time series\n",
    "item_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a925f1-ec77-47a5-a210-d423b042d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_item_metric(\n",
    "    item_metrics,\n",
    "    metric_name,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(15,6))\n",
    "\n",
    "    metric_data = item_metrics[metric_name]\n",
    "    ax.bar(item_metrics[FieldName.ITEM_ID], metric_data)\n",
    "\n",
    "    if len(item_metrics) > 1:\n",
    "        avg = metric_data.mean()\n",
    "        std = metric_data.std()\n",
    "        # Add average line\n",
    "        ax.axhline(avg, color='red', linestyle='--', label='Average')\n",
    "        # Add shaded area for standard deviation\n",
    "        ax.fill_between(range(len(item_metrics)), avg - std, avg + std, color='green', alpha=0.2, label='±1 Std Dev')\n",
    "    \n",
    "    ax.set_title(f'{metric_name} per item')\n",
    "    ax.set_ylabel(metric_name)\n",
    "    \n",
    "    # Show only horizontal grid lines\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef43511-9ff3-48fb-95ce-f679b9c0c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_item_metric(item_metrics, 'sMAPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eeaab7-a366-482e-92b6-a21e6d0f5726",
   "metadata": {},
   "source": [
    "#### Example 2: feedforward network\n",
    "Now use GluonTS's built-in fundamental neural network model [`SimpleFeedForwardEstimator`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/simple_feedforward/_estimator.py).\n",
    "\n",
    "`SimpleFeedForwardEstimator` implements a Multilayer Perceptron (MLP) model that predicts future time steps based on previous observations. The model produces probabilistic forecasts, meaning it outputs probability distributions rather than single point estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245d398-c925-4ec2-803d-10280dd9d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, _ = OffsetSplitter(offset=-prediction_length).split(ts_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0fb4-8207-4e77-80b2-8081339c91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_forward_estimator = SimpleFeedForwardEstimator(\n",
    "    num_hidden_dimensions=[10],\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=4*prediction_length,\n",
    "    trainer=Trainer(ctx=\"cpu\", epochs=5, learning_rate=1e-3, num_batches_per_epoch=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141a32a-408a-41c9-a45e-a97ce947074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_forward_predictor = feed_forward_estimator.train(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145d225-164c-48ee-b265-cae3b3be4a9c",
   "metadata": {},
   "source": [
    "To make forecast generation and evaluation easier, you can use GluonTS helper function\n",
    "[`make_evaluation_predictions`](https://ts.gluon.ai/stable/api/gluonts/gluonts.evaluation.html#gluonts.evaluation.make_evaluation_predictions). This function performs the following:\n",
    "1. Removes the last window of `prediction_length` data points from the dataset\n",
    "2. The estimator predicts the future `prediction_length` data points starting from the last point in the dataset\n",
    "3. Outputs the forecast samples and the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f744d-1edb-4441-8fc8-12437e33c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the last prediction_length data points of the dataset\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=ts_dataset, \n",
    "    predictor=feed_forward_predictor,\n",
    "    num_samples=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218ff1c-3f0b-43e1-bca1-81497576896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)\n",
    "labels = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1386cc-9c03-48f0-8e5e-3cba8dadcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "for i, forecast in enumerate(islice(forecasts, MAX_TS_TO_DISPLAY)):\n",
    "    plt.plot(labels[i][-2*prediction_length:].to_timestamp())\n",
    "    forecast.plot(intervals=(0.9,), show_label=True)\n",
    "    plt.legend([f\"Ground truth: {forecast.item_id}\", \"predicted median\", \"90% confidence interval\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e4b4f-64ea-48f3-ab4e-3a4a7cd5a78a",
   "metadata": {},
   "source": [
    "#### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9c33b-3e8f-48ad-8c4a-21cac41d673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=(np.arange(10) / 10.0)[1:])\n",
    "agg_metrics, item_metrics = evaluator(\n",
    "    labels, \n",
    "    forecasts,\n",
    "    num_series=len(ts_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be65289-b49c-45c9-9884-6c01a8458c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(agg_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7af73-f6fa-4c5f-a74f-aa50b11dd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813107b-f3eb-4e51-a8f3-4fb7ad6941b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_item_metric(item_metrics, 'sMAPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7775329-3271-4256-b49e-ebfd4b3ddf8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104b998-b941-4333-8620-7b76217bfcfe",
   "metadata": {},
   "source": [
    "## Train GluonTS models: advanced usage\n",
    "\n",
    "After learning some basic approaches to train and evaluate simple GluonTS models, you move to training of more advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494c63f-88e1-4af3-bedc-1216a57f975f",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "In this section you select time series and an inteval for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c86e91-4e2b-4f39-8b7d-c24e54581d3a",
   "metadata": {},
   "source": [
    "#### Choose time series\n",
    "Select the full dataset with all time series or only a subset of random or specific time series for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c76b8f-4a55-4a5b-b937-7d6d047075ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "To reduce the training time and inference time you can use a subset of time series instead of the full dataset with 370 time series.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329b2e4-9075-4050-a97d-82d92b835350",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FULL_DATASET = False # The training of full dataset can take about 40 minutes per estimator\n",
    "SAMPLE_SIZE = 10 # set number of samples in the dataset if you don't use the full dataset\n",
    "MAX_TS_TO_DISPLAY = 5 # maximum number of displayed time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa11a8-b44f-4812-9280-993bb7a1564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the full dataset or a random sample of SAMPLE_SIZE\n",
    "# you can change the selection to include specific time series\n",
    "# ts_sample = data_kw[['item_id1', 'item_id2']]\n",
    "ts_sample = data_kw if USE_FULL_DATASET else data_kw[np.random.choice(data_kw.columns.to_list(), size=SAMPLE_SIZE, replace=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024b0c5-b893-404a-b5a7-6a2853513a5c",
   "metadata": {},
   "source": [
    "#### Choose start and end dates\n",
    "Select the time interval for training and evaluation. Use the following visualization to choose your specific interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053268b-14b7-4468-ac6b-c033fd7f2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_training_date = pd.Timestamp('2014-01-01')\n",
    "end_dataset_date = pd.Timestamp('2014-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81b075-0e02-4928-9444-52234c529b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "item_ids = ts_sample.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cdbe0-8d3a-4694-b5a9-5414041e73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    item_ids=SelectMultiple(options=item_ids,value=[item_ids[0]], rows=5, style=style, description='Time series ids:'),\n",
    "    data_start=DatePicker(value=start_training_date, style=style, description='Data start:'),\n",
    "    data_end=DatePicker(value=end_dataset_date, style=style, description='Data end:'),\n",
    "    continuous_update=False,\n",
    ")\n",
    "def plot_interact(item_ids, data_start, data_end):\n",
    "\n",
    "    print(f'Filtering and displaying the data from {data_start} to {data_end}')\n",
    "    ts = ts_sample[(ts_sample.index > pd.Timestamp(data_start)) & (ts_sample.index <= pd.Timestamp(data_end))]\n",
    "\n",
    "    for i, item in enumerate(islice(item_ids, 2*MAX_TS_TO_DISPLAY)):\n",
    "        ts[item].plot(label=item, color=colors[i % len(colors)])\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b16759-a4dc-4539-a8ec-2df78c608d88",
   "metadata": {},
   "source": [
    "#### Convert to GluonTS format\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "If you want to use your own custom start and end dates, set them in the next code cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4007e48-7b8f-4af1-9bb8-14fe31564449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set interval start and end to your preferred dates\n",
    "start_training_date = pd.Timestamp('2014-01-01')\n",
    "end_dataset_date = pd.Timestamp('2014-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaaddf5-e1cd-431a-a680-00cf07490019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset = PandasDataset(\n",
    "    dict(ts_sample[(ts_sample.index > start_training_date) & (ts_sample.index <= end_dataset_date)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43888b-94b4-4e4f-aa15-a949dcd73fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show time series in the GluonTS dataset\n",
    "for i, entry in enumerate(islice(ts_dataset, MAX_TS_TO_DISPLAY)):\n",
    "    to_pandas(entry).plot(label=entry[FieldName.ITEM_ID], color=colors[i % len(colors)]) \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d40ea2-5ecd-4adc-9743-8fdaf33727bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The GluonTS dataset contains {len(ts_dataset)} individual time series from {start_training_date} to {end_dataset_date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9da6b-41ee-40a2-a641-52f80d408b65",
   "metadata": {},
   "source": [
    "### Split and prepare test instances\n",
    "\n",
    "For training and test you split data in multiple rolling windows starting from the end of the training dataset. You can choose the number of windows and whether windows overlap with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03eec38-4ad9-412e-ae1b-a754363091e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set backtest parameters\n",
    "NUM_WINDOWS = 4 # number of rolling windows for backtest\n",
    "# distance between windows, set to:\n",
    "# < prediction_length for overlapping windows\n",
    "# = prediction length for adjucent windows \n",
    "# > prediction_length for non overapping and non-adjucent windows\n",
    "DISTANCE = prediction_length\n",
    "\n",
    "# set the training-testing split date\n",
    "end_training_date = pd.Period(end_dataset_date, freq=freq) - NUM_WINDOWS*prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef803306-1e7f-46c6-b50c-9ec8e4a4bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_template = DateSplitter(date=end_training_date).split(ts_dataset)\n",
    "test_pairs = test_template.generate_instances(\n",
    "    prediction_length=prediction_length,\n",
    "    windows=NUM_WINDOWS,\n",
    "    distance=DISTANCE,\n",
    ")\n",
    "\n",
    "print(f\"The dataset is splitted in {len(train_ds)} training datasets and {len(test_pairs)} test pairs. Training end is {end_training_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941bf94-6774-476d-9f8d-f76b98446a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_splitting(ts_dataset, train_ds, test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15b9a4-c83e-4e7d-b914-4565edf82ed8",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e29d88-c824-40ae-ab9e-33ecb0077a63",
   "metadata": {},
   "source": [
    "Now you're ready to train models. To demonstrate some built-in GluonTS algorithms you going to train the following models:\n",
    "\n",
    "- [`SimpleFeedForward`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/simple_feedforward/_estimator.py)\n",
    "- [`NBEATS`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/n_beats/_estimator.py), [paper](https://openreview.net/forum?id=r1ecqn4YwB)\n",
    "- [`DeepAR`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/deepar/_estimator.py), [paper](https://doi.org/10.1016/j.ijforecast.2019.07.001) \n",
    "- [`GaussianProcess`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/gp_forecaster/_estimator.py)\n",
    "- [`TemporalFusionTransformer`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/tft/_estimator.py), [paper](https://doi.org/10.1016/j.ijforecast.2021.03.012)\n",
    "- [`MQCNN`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/mx/model/seq2seq/_mq_dnn_estimator.py), [paper](https://arxiv.org/abs/1711.11053)\n",
    "\n",
    "To compare performance of these models you're going to use statistical models like [`Seasonal Naive`](https://otexts.com/fpp2/simple-methods.html#seasonal-na%C3%AFve-method), [`Prophet`](https://facebook.github.io/prophet/), and [`NTPS`](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/model/npts/_predictor.py) as a baseline.\n",
    "\n",
    "You can experiment with other [available models](https://ts.gluon.ai/stable/getting_started/models.html) on your own using the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b8589-b35a-4a74-9264-c3627744efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove an item from this list if you don't want to train that model\n",
    "estimators_to_train = [\n",
    "    'SimpleFeedForward', \n",
    "    'NBEATS', \n",
    "    'DeepAR',\n",
    "    'GaussianProcess', \n",
    "    'TemporalFusionTransformer', \n",
    "    'MQCNN', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9e0d7-b219-4a6c-bd5c-42560e273611",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: left; margin: auto;\">\n",
    "<b>Important considerations</b><br/>\n",
    "1. This example is not production-grade model training<br/>\n",
    "2. All estimators are trained with default hyperparameters which might not be the optimal configuration<br/>\n",
    "3. All training is limited to 8 epochs which might not yield the most optimal model<br/>\n",
    "4. This notebook uses CPU-only MXNet implementation of all shown neural network models<br/>\n",
    "5. In a real-world use case you're going to use an ensemble of several models rather than a single model<br/>\n",
    "6. In a real-world use case you might run a hyperparameter optimization as well<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa21ad0-dbc9-431e-9da3-8875e049ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 8\n",
    "trainer_hyperparameters = {\n",
    "    \"ctx\":\"cpu\",\n",
    "    \"epochs\":NUM_EPOCHS,\n",
    "    \"learning_rate\":01e-3,\n",
    "    \"clip_gradient\":10,\n",
    "    \"weight_decay\":1e-8,\n",
    "    \"num_batches_per_epoch\":100,\n",
    "}\n",
    "\n",
    "# same trainer for all models\n",
    "trainer = Trainer(**trainer_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd1de4-c0c6-4490-855b-77860ace5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {}\n",
    "model_hyperparameters = {\n",
    "    \"freq\":freq,\n",
    "    \"prediction_length\":prediction_length,\n",
    "    \"context_length\":4*prediction_length,\n",
    "    \"trainer\":trainer,\n",
    "}\n",
    "\n",
    "for e in estimators_to_train:\n",
    "    if e == 'SimpleFeedForward':\n",
    "        estimators[e] = SimpleFeedForwardEstimator(\n",
    "            num_hidden_dimensions=[10],\n",
    "            prediction_length=prediction_length,\n",
    "            context_length=4*prediction_length,\n",
    "            trainer=trainer\n",
    "        )\n",
    "    elif e == 'NBEATS':\n",
    "        estimators[e] = NBEATSEstimator(\n",
    "            **model_hyperparameters,\n",
    "            loss_function='MAPE',\n",
    "            num_stacks=30,\n",
    "            widths=[512],\n",
    "            num_blocks=[1],\n",
    "        )\n",
    "    elif e == 'DeepAR':\n",
    "        estimators[e] = DeepAREstimator(\n",
    "            **model_hyperparameters,\n",
    "        )\n",
    "    elif e == 'GaussianProcess':\n",
    "        estimators[e] = GaussianProcessEstimator(\n",
    "            **model_hyperparameters,\n",
    "            cardinality=len(train_ds),\n",
    "        )\n",
    "    elif e == 'TemporalFusionTransformer':\n",
    "        estimators[e] = TemporalFusionTransformerEstimator(\n",
    "            **model_hyperparameters,\n",
    "        )\n",
    "    elif e == 'MQCNN':\n",
    "        estimators[e] = MQCNNEstimator(\n",
    "            **model_hyperparameters,\n",
    "        )\n",
    "    elif e == 'MQRNN':\n",
    "        estimators[e] = MQRNNEstimator(\n",
    "            **model_hyperparameters,\n",
    "        )\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(f'Configured estimators: {[k for k in estimators.keys()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3908c6c-2147-42f0-a897-58b9501a4b40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "With six given estimators and 10 time series the training takes about <b>60 minutes</b>. You can take only a subset of estimators to reduce training time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9ebbd-5169-4830-b676-434014ab09be",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1c3f8-0b14-4998-837c-31d8a83e98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training {len(estimators.keys())} estimators on {len(train_ds)} time series.')\n",
    "print(f'Estimators: {[k for k in estimators.keys()]}')\n",
    "\n",
    "# train all estimators and store predictors in a dict\n",
    "predictors = {\n",
    "    n:e.train(train_ds) for n, e in estimators.items()\n",
    "}\n",
    "\n",
    "# add statistical models that don't need training for a baseline\n",
    "predictors['SeasonalNaive'] = SeasonalNaivePredictor(prediction_length=prediction_length, season_length=24)\n",
    "predictors['Prophet'] = ProphetPredictor(prediction_length=prediction_length)\n",
    "predictors['NPTS'] = NPTSPredictor(prediction_length=prediction_length, context_length=4*prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751a794-065c-4cb8-8835-3dca92bcef41",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14b18f-5efe-4aa2-b2d9-24ac8d7c3797",
   "metadata": {},
   "source": [
    "### Predict and visualize\n",
    "Having all predictors you can generate forecasts for each test interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cea61-a530-4085-8bf6-837ddadc35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running inference for {len(predictors.keys())} predictors on {len(test_pairs)} test datasets: {NUM_WINDOWS} rolling windows*{len(ts_dataset)} time series\")\n",
    "print(f'Predictors: {[k for k in predictors.keys()]}')\n",
    "\n",
    "# generate forecast for each test pair and each predictor and save to a dict\n",
    "forecasts_all = {\n",
    "    n:list(p.predict(test_pairs.input, num_samples=20)) for n, p in predictors.items()\n",
    "}\n",
    "\n",
    "# ground truth\n",
    "labels = [to_pandas(l) for l in test_pairs.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302b1e1-16ad-4215-9103-c11d3d2f1747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(\n",
    "    item_id,\n",
    "    original_dataset, # GluonTS PandasDataset\n",
    "    forecasts, # iterator with predicted forecasts\n",
    "    labels, # test_pairs.label iterator\n",
    "    prediction_length,\n",
    "    history_length, # how much of history are displayed\n",
    "    c_interval=0.9, # confidence interval for probabilistic predictions\n",
    "):\n",
    "    # Get historical data, predictions, and label for the specific item_id\n",
    "    historical_ts = to_pandas([e for e in original_dataset if e[FieldName.ITEM_ID] == item_id][0])\n",
    "    item_forecasts = [f for f in forecasts if f.item_id == item_id]\n",
    "    item_labels = [to_pandas(l) for l in labels if l[FieldName.ITEM_ID] == item_id]\n",
    "    \n",
    "    # Calculate the number of rows needed for the grid\n",
    "    n_forecasts = len(item_forecasts)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_forecasts +1) // n_cols\n",
    "    \n",
    "    # Create figure for historical data\n",
    "    fig_hist, ax_hist = plt.subplots(figsize=(15, 3))\n",
    "    plt.plot(historical_ts[-history_length:].to_timestamp(), color='b', label='Historical')\n",
    "    ax_hist.set_title(f'Historical time series: {item_id}')\n",
    "    ax_hist.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create figure for forecasts\n",
    "    fig_forecasts, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    # Plot each forecast\n",
    "    for idx, (label, forecast) in enumerate(zip(item_labels, item_forecasts)):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot ground truth\n",
    "        ax.plot(label.to_timestamp(), color='g', label='Ground truth')\n",
    "        \n",
    "        # Plot forecast with confidence interval\n",
    "        forecast.plot(ax=ax, intervals=(c_interval,), show_label=True, color='r')\n",
    "        \n",
    "        ax.set_title(f'Prediction interval {idx}, start: {forecast.start_date}')\n",
    "    \n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(item_forecasts), len(axes)):\n",
    "        fig_forecasts.delaxes(axes[idx])\n",
    "    \n",
    "    fig_forecasts.legend(['Ground truth', 'Predicted median', f'{c_interval*100:.0f}% confidence interval'], \n",
    "                        loc='upper center', \n",
    "                        bbox_to_anchor=(0.5, 1.0),\n",
    "                        ncol=3,  # Display legend items in 3 columns\n",
    "                        bbox_transform=fig_forecasts.transFigure)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Adjust layout to account for the legend\n",
    "    plt.subplots_adjust(top=0.85, hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c11d8b-86b2-4651-8e5b-df5e22abeb8c",
   "metadata": {},
   "source": [
    "In the following interactive visualization you can display historical data, predictions and ground truth for each evaluation window for a specific time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d1dc6-7ee5-4cb4-adf6-c647da27cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "item_ids = [e[FieldName.ITEM_ID] for e in ts_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440d100-d7cf-47f2-b869-59f9a2bfd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    model=Dropdown(options=list(forecasts_all.keys()), description='Model:'),\n",
    "    item_id=Select(options=item_ids, value=item_ids[0], rows=5, style=style, description='Item id:'),\n",
    ")\n",
    "def plot_interact(model, item_id):\n",
    "    visualize_predictions(\n",
    "        item_id, \n",
    "        ts_dataset, \n",
    "        forecasts_all[model],\n",
    "        test_pairs.label,\n",
    "        prediction_length,\n",
    "        NUM_WINDOWS*prediction_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc5ea0-fe24-426f-8174-40e329a43f74",
   "metadata": {},
   "source": [
    "If you'd like to compare performance across models and compare models per metric, run the following cells to save the results to a file and open the notebook [`lab6_results`](../lab6_results.ipynb) for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9096a45-74c4-4c9a-b99d-ff047677260d",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74cc39-8473-4d3e-9409-9c55ce6e1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Scoring {len(forecasts_all.keys())} forecasts on {len(test_pairs)} test pairs: {NUM_WINDOWS} rolling windows*{len(ts_dataset)} time series\")\n",
    "print(f'Predictors: {[k for k in predictors.keys()]}')\n",
    "\n",
    "evaluator = Evaluator(quantiles=(np.arange(10) / 10.0)[1:])\n",
    "\n",
    "backtest_scores = []\n",
    "\n",
    "# calculate metrics for all predictors\n",
    "for n, f in forecasts_all.items():\n",
    "    agg_metrics, item_metrics = evaluator(\n",
    "        labels, \n",
    "        f,\n",
    "    )\n",
    "    backtest_scores.append({'model':n, 'agg_metrics':agg_metrics, 'item_metrics':item_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce252482-9e10-4ef9-8721-3086f21e545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "item_ids = backtest_scores[0]['item_metrics'][FieldName.ITEM_ID].unique()\n",
    "metrics = backtest_scores[0]['item_metrics'].columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbf270-0d04-4116-a57c-308a0b0cf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    model=Dropdown(options=list(forecasts_all.keys()), description='Model:'),\n",
    "    metric=Select(options=metrics, value=metrics[0], rows=20, style=style, description='Metric:'),\n",
    ")\n",
    "def plot_interactive(model, metric):\n",
    "    agg_metrics, item_metrics = [(m['agg_metrics'], m['item_metrics']) for m in backtest_scores if m['model'] == model][0]\n",
    "\n",
    "    visualize_item_metric(item_metrics, metric)\n",
    "    print(f'Aggregated metrics for {model} model:\\n{json.dumps(agg_metrics, indent=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad8d2e-ba34-4515-8eac-5fb6580473ea",
   "metadata": {},
   "source": [
    "#### Save the model performance to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee198b-97c0-45a4-ae98-7bad39b4e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_prefix = \"gluonts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2360d43-e15b-4357-bcaf-13068b4c43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../model-performance\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241d996-990e-4d18-a8bd-0fcfc7d651dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_df(\n",
    "    model_metrics: dict,\n",
    "    experiment_name: str,\n",
    "    timestamp=strftime(\"%Y%m%d-%H%M%S\", gmtime()),\n",
    ") -> pd.DataFrame:\n",
    "    model_metrics_df = pd.DataFrame.from_dict(model_metrics, orient='index', columns=['value']).reset_index().rename(columns={'index': 'metric_name'})\n",
    "    model_metrics_df['experiment'] = experiment_name\n",
    "    model_metrics_df['timestamp'] = timestamp\n",
    "    model_metrics_df = model_metrics_df[['timestamp', 'metric_name', 'value', 'experiment']].dropna(subset=['value'])\n",
    "\n",
    "    # print(model_metrics_df)\n",
    "    return model_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862f08b-8c90-46dc-a594-c6b753224121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a DataFrame with all metrics for all models\n",
    "model_metrics_df = pd.concat([\n",
    "    get_metrics_df(\n",
    "        s['agg_metrics'],\n",
    "        f\"{experiment_prefix}-{s['model']}-{freq}-{len(ts_dataset)}-{len(next(iter(ts_dataset))[FieldName.TARGET])}-bt{NUM_WINDOWS}\",\n",
    "    ) for s in backtest_scores\n",
    "])\n",
    "\n",
    "model_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba53302-7d4e-42ad-8838-7251464d45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the metrics df to the file\n",
    "experiment_name = f\"{experiment_prefix}-{freq}-{len(ts_dataset)}-{len(next(iter(ts_dataset))[FieldName.TARGET])}-bt{NUM_WINDOWS}\"\n",
    "\n",
    "model_metrics_df.to_csv(\n",
    "    f\"../model-performance/{experiment_name}-{model_metrics_df['timestamp'].iloc[0]}.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f6390-1d4a-48e2-a6c5-8a184b814002",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab023a-7aff-49c3-b371-067fea556a6a",
   "metadata": {},
   "source": [
    "## Optional: operationalizing GluonTS training and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1471051-4259-41c1-99cd-63a7fd2b4754",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "This section is <b>L300-400</b> level and assumes you're familiar with MLOps concepts, SageMaker features like pipelines, training jobs, and model registry. Completion time for this section is about <b>60 minutes</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78d0db-8a65-4b52-9189-654cf2eb413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43395ae3-934c-45b2-a0d5-bebff44d2f9e",
   "metadata": {},
   "source": [
    "In this section you create a production-ready ML workflow to preprocess an input dataset, train a time series model, evaluate the model, register model in the model registry, and deploy model as a SageMaker real-time inference endpoint.\n",
    "\n",
    "This notebook uses the PyTorch implementation of [Temporal Fusion Transformer](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/torch/model/tft/estimator.py) as a model example. This model is one of the GluonTS built-in algorithms that you can use out of the box.\n",
    "\n",
    "On this example you learn how to use [SageMaker MLOps features](https://aws.amazon.com/sagemaker/mlops/) and [Python SDK](https://sagemaker.readthedocs.io/en/stable/index.html) to create robust, reproducable, portable, and scalable ML solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107cace-6083-48ed-80a9-92f31d3307ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to check resource quota in the account\n",
    "def check_quota(q_map, instance, min_n=1):\n",
    "    quotas_client = boto3.client(\"service-quotas\")\n",
    "\n",
    "\n",
    "    r = quotas_client.get_service_quota(\n",
    "        ServiceCode=\"sagemaker\",\n",
    "        QuotaCode=q_map[instance],\n",
    "    )\n",
    "\n",
    "    q = r[\"Quota\"][\"Value\"]\n",
    "    n = r[\"Quota\"][\"QuotaName\"]\n",
    "    min_n = min_n\n",
    "\n",
    "    b = q >= min_n\n",
    "\n",
    "    print(f\"\\033[92mSUCCESS: Quota {q} for {n} >= required {min_n}\\033[0m\" if b else f\"\\033[91mWARNING: Quota {q} for {n} < required {min_n}\\033[0m\")\n",
    "\n",
    "    return b\n",
    "    \n",
    "# helper to get the first available instance in the quota map\n",
    "def get_best_instance(q_map):\n",
    "    l = [i for i in\n",
    "            [i if check_quota(q_map, i) else None \n",
    "             for i in q_map.keys()] if i is not None]\n",
    "    return l[0] if len(l) > 0 else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407b296-de2c-4a2e-84e6-e977096a1ce8",
   "metadata": {},
   "source": [
    "### Configure defaults of AWS infrastructure\n",
    "Here you use a YAML configuration file to define the default values that are automatically passed to SageMaker APIs, for example as job parameters. It's especially convenient when you need to provide static parameters for infrastructure settings, such as VPC ids, Security Groups, KMS keys etc, or work with remote functions.\n",
    "\n",
    "Refer to [Configuring and using defaults with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk) documentation for examples and more details.\n",
    "\n",
    "Your GluonTS pipeline will use these `config.yaml` files for the default configuration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ff94c-6cf6-4485-b6fd-177ae1befac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print default location of configuration files\n",
    "from platformdirs import site_config_dir, user_config_dir\n",
    "\n",
    "#Prints the location of the admin config file\n",
    "print(os.path.join(site_config_dir(\"sagemaker\"), \"config.yaml\"))\n",
    "\n",
    "#Prints the location of the user config file\n",
    "print(os.path.join(user_config_dir(\"sagemaker\"), \"config.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a49fa9-f4ff-4624-8b56-25dd6276cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "SchemaVersion: '1.0'\n",
    "SageMaker:\n",
    "    PythonSDK:\n",
    "        Modules:\n",
    "            RemoteFunction:\n",
    "                InstanceType: ml.m5.2xlarge\n",
    "                Dependencies: ./requirements.txt\n",
    "                IncludeLocalWorkDir: true\n",
    "                CustomFileFilter:\n",
    "                    IgnoreNamePatterns: # files or directories to ignore\n",
    "                        - \"*.ipynb\" # all notebook files\n",
    "                        - \"*.md\" # all markdown files\n",
    "                        - \"__pycache__\"\n",
    "                        - \"*.zip\"\n",
    "                        - \"*.gz\"\n",
    "                        - \"LD2011_2014.*\"\n",
    "                        - \"*local\"\n",
    "                        - \"*logs\"\n",
    "                        - \"*data\"\n",
    "                        - \"*output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2f34a-c369-4e7e-8e20-b7b3548567f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the configuration file to user config file location\n",
    "%mkdir -p {user_config_dir(\"sagemaker\")}\n",
    "%cp config.yaml {os.path.join(user_config_dir(\"sagemaker\"), \"config.yaml\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d148a2b-5844-4856-aa70-9c40a26febdf",
   "metadata": {},
   "source": [
    "### Prepare environment\n",
    "\n",
    "Import required packages, create a `requirements.txt` file for SageMaker processing and training job, and create local source code directories for local mode execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b50a5d-2219-47e0-8e76-755876e68855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.local import LocalSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbacc36-4b03-4bad-a026-c14635a7c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "sentencepiece==0.1.99\n",
    "lightning\n",
    "gluonts>=0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e93007-8c16-46ba-bc49-ea36b8b3057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./requirements.txt ./gluonts_pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bd09d-044d-47e4-86b6-0b675c160912",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -rf ./gluonts_pipeline_local/\n",
    "!mkdir -p ./gluonts_pipeline_local/\n",
    "!mkdir -p ./output/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0ca41-3567-4aed-a37f-8660a1b6ffec",
   "metadata": {},
   "source": [
    "#### Configure for local mode\n",
    "Amazon SageMaker Studio applications support the use of local mode to create estimators, processors, and pipelines. With local mode, you can test your scripts locally in JupyterLab before running them in SageMaker managed training or hosting environments. The local mode is a convenient way to quickly iterate over your training script in the notebook to ensure it works as intended.  Refer to [Local mode support in Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-local.html) to understand which docker operations the Studio currently supports.\n",
    "\n",
    "To use local mode in Studio applications, you must enable docker access for the Sagemaker domain and  install Docker into your JupyterLab space.\n",
    "\n",
    "This section checks if docker access is enabled in the domain, installs Docker, and installs the `sagemaker[local]` extras from the sagemaker SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9b401-22fc-4411-ac95-6bfc4c40c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that docker enabled in the SageMaker domain\n",
    "docker_settings = boto3.client('sagemaker').describe_domain(DomainId=domain_id)['DomainSettings'].get('DockerSettings')\n",
    "docker_enabled = False\n",
    "\n",
    "if docker_settings:\n",
    "    if docker_settings.get('EnableDockerAccess') in ['ENABLED']:\n",
    "        print(f\"\\033[92mThe docker access is ENABLED in the domain {domain_id}\\033[0m\")\n",
    "        docker_enabled = True\n",
    "\n",
    "if not docker_enabled:\n",
    "    raise Exception(f\"\\033[91mYou must enable docker access in the domain to use Studio local mode\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d07585-e0c7-4c89-a82a-d29e0b1e55ed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "If docker is not enabled, you need to enable the access following the instructions below. You may also skip the <b>Run and test pipeline steps locally</b> section and go directly to the <b>Construct a pipeline</b> section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924860f-c63f-40ad-aad2-935276d9b6a0",
   "metadata": {},
   "source": [
    "**To enable Docker access in the SageMaker domain**:\n",
    "\n",
    "If you have the corresponding permissions in the notebook execution role, you can run the following code in a notebook:\n",
    "\n",
    "```Python\n",
    "import boto3\n",
    "\n",
    "r = boto3.client('sagemaker').update_domain(\n",
    "    DomainId=domain_id,\n",
    "    DomainSettingsForUpdate={\n",
    "        'DockerSettings': {\n",
    "            'EnableDockerAccess':'ENABLED',\n",
    "        }\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "Alternatively run can run `aws sagemaker` CLI in the terminal:\n",
    "\n",
    "```sh\n",
    "aws sagemaker update-domain --domain-id <DOMAIN-ID> --domain-settings-for-update DockerSettings={EnableDockerAccess='ENABLED'}\n",
    "```\n",
    "\n",
    "For both options your execution role needs to have `sagemaker:UpdateDomain` permission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d5111-df47-422d-8c1a-b8b624cf338b",
   "metadata": {},
   "source": [
    "#### Install Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e4f86-4a35-4f5f-9e62-388b0a64e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# see https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y ca-certificates curl\n",
    "sudo install -m 0755 -d /etc/apt/keyrings\n",
    "sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n",
    "sudo chmod a+r /etc/apt/keyrings/docker.asc\n",
    "\n",
    "# Add the repository to Apt sources:\n",
    "echo \\\n",
    "  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n",
    "  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n",
    "  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "sudo apt-get update\n",
    "\n",
    "## Currently only Docker version 20.10.X is supported in Studio: see https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-local.html\n",
    "# pick the latest patch from:\n",
    "# apt-cache madison docker-ce | awk '{ print $3 }' | grep -i 20.10\n",
    "VERSION_STRING=5:20.10.24~3-0~ubuntu-jammy\n",
    "sudo apt-get install docker-ce-cli=$VERSION_STRING docker-compose-plugin -y\n",
    "\n",
    "# validate the Docker Client is able to access Docker Server at [unix:///docker/proxy.sock]\n",
    "docker version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ac773-070e-4afa-a314-3f6abaf15781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q sagemaker[local]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44ae69-a11a-4bbf-b53e-14b4069a851d",
   "metadata": {},
   "source": [
    "### Upload the raw dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f372f-09d3-4e22-9ec5-b2188ee3cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set S3 urls for input and output data\n",
    "s3_input_data_prefix = f's3://{s3_bucket}/{s3_prefix}/data/raw'\n",
    "s3_output_data_prefix = f's3://{s3_bucket}/{s3_prefix}/data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb586f2-f461-4b9c-8962-07511e5117ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all previous datasets on S3\n",
    "!aws s3 rm s3://{s3_bucket}/{s3_prefix}/data/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb1c31-c6aa-49bd-a0c6-97addcf6852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the original zip file with the dataset to S3\n",
    "!aws s3 cp {extract_to_path}/{dataset_zip_file_name} {s3_input_data_prefix}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64442a-6131-4694-b1c4-6eabbdd5648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that the dataset is copied on S3\n",
    "!aws s3 ls s3://{s3_bucket}/{s3_prefix}/data/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd887d3c-1175-4f6d-af8a-a52adff4522f",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "\n",
    "Set values for parameters passed to the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc5eac-efe6-4c82-b85b-094e1eb7ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# portion of the whole dataset used\n",
    "data_start = pd.Timestamp('2014-01-01')\n",
    "data_end = pd.Timestamp('2014-12-31')\n",
    "\n",
    "# hyperparameters for training\n",
    "# for more hyperparameters see https://github.com/awslabs/gluonts/blob/dev/src/gluonts/torch/model/tft/estimator.py\n",
    "# extend the hyperparameters dictionary to additional hp to the estimator. You also need to adapt train.py\n",
    "hyperparameters = {\n",
    "    \"epochs\":8,\n",
    "    \"freq\":freq,\n",
    "    \"prediction_length\":prediction_length,\n",
    "    \"context_length\":4*prediction_length,\n",
    "    \"quantiles\":','.join(str(x) for x in (np.arange(10) / 10.0)[1:]),\n",
    "    \"backtest_windows\":4,\n",
    "    \"num_samples\":20, # not used in TFT predictor\n",
    "}\n",
    "\n",
    "# define metrics which should be collected by SageMaker\n",
    "metric_definitions = [\n",
    "    {'Name':'train_loss', 'Regex':'train_loss=([0-9\\.]+)'},\n",
    "    {'Name':'test_MSE', 'Regex':'test_MSE=([0-9\\.]+)'},\n",
    "    {'Name':'test_MAPE', 'Regex':'test_MAPE=([0-9\\.]+)'},\n",
    "    {'Name':'test_sMAPE', 'Regex':'test_sMAPE=([0-9\\.]+)'},\n",
    "    {'Name':'test_RMSE', 'Regex':'test_RMSE=([0-9\\.]+)'},\n",
    "    {'Name':'test_mean_wQuantileLoss', 'Regex':'test_mean_wQuantileLoss=([0-9\\.]+)'},\n",
    "    {'Name':'test_mean_absolute_QuantileLoss', 'Regex':'test_mean_absolute_QuantileLoss=([0-9\\.]+)'},\n",
    "]\n",
    "\n",
    "# where to store training artefacts\n",
    "s3_output_train_prefix = f's3://{s3_bucket}/{s3_prefix}/train/output'\n",
    "\n",
    "# model package group name in the Model Registry\n",
    "model_package_group_name = 'gluonts-tft-local'\n",
    "\n",
    "# PyTorch Deep Learning Container framework version\n",
    "dlc_framework_version = '2.3'\n",
    "python_version = 'py311'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07c644-df70-4397-85c7-be62b70ffd71",
   "metadata": {},
   "source": [
    "### Run and test pipeline steps locally\n",
    "\n",
    "In this section you develop and test preprocessing and training step of the workflow locally before combining all steps into a pipeline.\n",
    "\n",
    "You create the following pipeline:\n",
    "\n",
    "| Step | Description |\n",
    "|---|---|\n",
    "| **Data processing** | runs a processing job to extract a sample of time series from the whole dataset and to perform dataset split into train and test|\n",
    "| **Training and evaluation** | runs a SageMaker training job using PyTorch container and `TemporalFusionTransformer` estimator. After training, the job evaluates model performance on a hold-out dataset |\n",
    "| **Conditional step** | checks if model performance meets the specified threshold |\n",
    "| **Register model** | registers a version of the model in the SageMaker model registry |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e00a6-8e4a-49c5-8d58-8b74cda6fdf9",
   "metadata": {},
   "source": [
    "#### Preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07b039-497c-4d3a-b32c-517b4f926160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function code is in the local files\n",
    "from gluonts_pipeline.preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffcbfb-cea2-47bd-ae06-f83324bb626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_preprocess = preprocess(\n",
    "    input_data_s3_path = f'{s3_input_data_prefix}/{dataset_zip_file_name}',\n",
    "    output_s3_prefix=s3_output_data_prefix,\n",
    "    freq=freq,\n",
    "    prediction_length=prediction_length,\n",
    "    data_start=data_start,\n",
    "    data_end=data_end,\n",
    "    backtest_windows=4,\n",
    "    sample_size=10,  # set to 0 to use the full dataset with 370 series\n",
    ")\n",
    "r_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd93276-bcb9-4496-9efd-0f537f4f09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that the dataset is copied on S3\n",
    "!aws s3 ls {s3_output_data_prefix}/{r_preprocess['pipeline_run_id']} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee37998-5387-4c5a-b500-6c4634db6aed",
   "metadata": {},
   "source": [
    "#### Training step\n",
    "\n",
    "This section demonstrates two options for implementing GluonTS training. \n",
    "\n",
    "Option 1 is to run a custom training script as a remote function using `@step` decorator. Option 2 is to use a [SageMaker SDK framework for PyTorch](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html) and leverage the built-in [SageMaker Deep Learning Containers (DLC)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md).\n",
    "\n",
    "This section uses Option 2 because it requires less effort for training artefact management and allows model deployment with one line of code from a trained estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8a6c2-2cc8-4d17-9e4e-e2ba1548a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts_pipeline.train_step import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834f17a-9d68-4b45-a208-66214e35f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input datasets for training\n",
    "# these datasets are prepared and uploaded to S3 by the preprocessing step\n",
    "training_inputs = {\n",
    "    'train': r_preprocess['train_data'],\n",
    "    'test': r_preprocess['test_data'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d419f24-e451-4136-948e-76947edd91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: use local training script and then @step decorator for the pipeline step\n",
    "# This code is given for your reference\n",
    "# r_train = train(\n",
    "#     train_data_s3_path=r_preprocess['train_data'],\n",
    "#     test_data_s3_path=r_preprocess['test_data'],\n",
    "#     output_s3_prefix=s3_output_train_prefix,\n",
    "#     hyperparameters=hyperparameters,\n",
    "# )\n",
    "# r_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f1b0b-d71e-45c9-bca1-09e3d9d8b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy scripts and requirements.txt to the dedicated directory\n",
    "!cp -rf ./gluonts_pipeline/* ./gluonts_pipeline_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928315ff-8e16-4b36-849e-08c5f39cf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a local session\n",
    "LOCAL_SESSION = LocalSession()\n",
    "LOCAL_SESSION.config = {'local': {'local_code': True}}  # Ensure full code locality, see: https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3f10a-78c9-4026-bbff-7c75a5eb78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: use a PyTorch estimator class\n",
    "# note use of 'local' as instance_type parameter for local mode\n",
    "tft_estimator_local = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='gluonts_pipeline_local',\n",
    "    framework_version=dlc_framework_version,  \n",
    "    py_version=python_version,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=sm_role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    output_path=s3_output_train_prefix,\n",
    "    base_job_name=\"gluonts-pipeline-training\",\n",
    "    sagemaker_session=LOCAL_SESSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8371b1e-fd38-4393-b8f2-067e3ec3735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training in a Docker container locally in the notebook\n",
    "# the first run takes longer because the container must be pulled\n",
    "tft_estimator_local.fit(training_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc5202-5aea-42f9-8b06-2ebc97145162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate that the train artefacts are uploaded to S3\n",
    "!aws s3 ls {s3_output_train_prefix}/{tft_estimator_local._current_job_name} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6023a-7ea0-40d4-871f-e59f5c4459ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model metrics and extract to the local volume\n",
    "!aws s3 cp {s3_output_train_prefix}/{tft_estimator_local._current_job_name}/output . --recursive\n",
    "!tar -xvf ./output.tar.gz -C output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24de9e-e59a-4f3b-ae27-0d0a5fc3837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display aggregated test metrics\n",
    "with open('output/data/agg_metrics.json', 'r') as f:\n",
    "    agg_metrics = json.load(f)\n",
    "\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13667837-9628-484c-98e6-79c32eff722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display item-level metrics\n",
    "item_metrics = pd.read_csv(\"output/data/item_metrics.csv.gz\", compression=\"gzip\")\n",
    "visualize_item_metric(item_metrics, 'sMAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a87b9-3e01-4c6f-ae18-632c3c6a3511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can load the saved model from disk into a predictor \n",
    "!tar -xvf ./model.tar.gz -C output/model/\n",
    "predictor_deserialized = Predictor.deserialize(Path(\"./output/model\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89113ad5-c737-4232-82c4-d99c26eaebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the last prediction_length data points of the test dataset\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=ListDataset(JsonLinesFile(Path('./data/test.jsonl.gz')), freq=freq), \n",
    "    predictor=predictor_deserialized,\n",
    "    num_samples=20\n",
    ")\n",
    "forecasts = list(forecast_it)\n",
    "labels = list(ts_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2794bd-992f-4743-9fe9-519fcaa3787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot forecasts\n",
    "for i, f in enumerate(islice(forecasts, MAX_TS_TO_DISPLAY*2)):\n",
    "    plt.title(f'Time series: {f.item_id}')\n",
    "    plt.plot(labels[0][-prediction_length:].to_timestamp(), linewidth=3)\n",
    "    f.plot(color=colors[i % len(colors)], show_label=True)\n",
    "    plt.legend(['Historical', 'Predicted median', '90% confidence interval'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9077a-0c37-404e-bc54-064884bd1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also run the training job remotely on a specified instance type\n",
    "# tft_estimator = PyTorch(\n",
    "#     entry_point='train.py',\n",
    "#     source_dir='gluonts_pipeline',\n",
    "#     framework_version=dlc_framework_version,  \n",
    "#     py_version=python_version,\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     role=sm_role,\n",
    "#     instance_count=1,\n",
    "#     instance_type='ml.g5.4xlarge',\n",
    "#     output_path=s3_output_train_prefix,\n",
    "#     base_job_name=\"gluonts-pipeline-training\",\n",
    "#     metric_definitions=metric_definitions,\n",
    "# )\n",
    "\n",
    "# tft_estimator.fit(training_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d9cd5-fdc3-4847-a104-b7a5b543042b",
   "metadata": {},
   "source": [
    "#### Model registration step\n",
    "\n",
    "This step registers a new trained model version in the SageMaker model registry within a [model package group](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-model-group.html). This step is implemented as a local Python function that runs remotely during execution of the pipeline.\n",
    "\n",
    "If you don't have a completed training job, skip this step and go to **Construct a pipeline**. The model registration implementation requires a completed training job to attach an estimator and to register a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a3a63-9812-46c8-9299-f269108bba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts_pipeline.register import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a19f2-bbf8-4e9e-a6ba-cc8d920e5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_register = register(\n",
    "#     training_job_name=<TRAINING JOB NAME>,\n",
    "#     model_package_group_name=model_package_group_name,\n",
    "#     pipeline_run_id=r_preprocess['pipeline_run_id']\n",
    "# )\n",
    "# r_register"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49064101-03a5-4564-867c-7cbc3d111652",
   "metadata": {},
   "source": [
    "### Construct a pipeline\n",
    "After local testing you can use the same Python code without any changes to construct a pipeline.\n",
    "\n",
    "The next cell creates a pipeline with previously developed and tested steps.\n",
    "\n",
    "You don't need to manually define an ordering of the steps, as SageMaker automatically derives the processing flow based on data dependencies between pipeline's steps. You also don't need to manage transfer of artifacts and datasets from one pipeline's step to another, because SageMaker automatically takes care of the data flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d48bd-828f-47c2-a429-be337f9a5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.steps import (\n",
    "    TrainingStep, \n",
    "    CacheConfig\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig \n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead09b62-a0b2-489b-b922-4f5b3933de9c",
   "metadata": {},
   "source": [
    "#### Define pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f349bd1-d032-4090-889d-d07cb0aee3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quota codes for training and processing job instances\n",
    "prc_instance_map = {\n",
    "    'ml.c5.4xlarge':'L-E7898792',\n",
    "    'ml.c5.2xlarge':'L-49679826',\n",
    "    'ml.m5.xlarge':'L-CCE2AFA6'\n",
    "}\n",
    "\n",
    "trn_instance_map = {\n",
    "    'ml.g5.4xlarge':'L-FE869B40',\n",
    "    'ml.g5.2xlarge':'L-2D6DEB3C',\n",
    "    **prc_instance_map,\n",
    "}\n",
    "\n",
    "# define unique pipeline and model registry package group name\n",
    "timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "pipeline_name = f'gluonts-pipeline-{timestamp}'\n",
    "model_package_group_name = f'gluonts-tft-{timestamp}'\n",
    "\n",
    "# get processing and training instances based on the available account quotas\n",
    "processing_instance_type = get_best_instance(prc_instance_map)\n",
    "training_instance_type = get_best_instance(trn_instance_map)\n",
    "\n",
    "# define pipeline parameters\n",
    "pipeline_parameters = {\n",
    "    'processing_instance_type':ParameterString(name='processing_instance_type', default_value=processing_instance_type),\n",
    "    'training_instance_type':ParameterString(name='training_instance_type', default_value=training_instance_type),\n",
    "    'input_data_s3_path':ParameterString(name='input_data_s3_path', default_value=f'{s3_input_data_prefix}/{dataset_zip_file_name}'),\n",
    "    's3_output_data_prefix':ParameterString(name='s3_output_data_prefix', default_value=s3_output_data_prefix),\n",
    "    's3_output_train_prefix':ParameterString(name='s3_output_train_prefix', default_value=s3_output_train_prefix),\n",
    "    'freq':ParameterString(name='freq', default_value=freq),\n",
    "    'prediction_length':ParameterInteger(name='prediction_length', default_value=prediction_length),\n",
    "    'data_start':ParameterString(name='data_start', default_value=str(data_start)),\n",
    "    'data_end':ParameterString(name='data_end', default_value=str(data_end)),\n",
    "    'backtest_windows':ParameterInteger(name='backtest_windows', default_value=4),\n",
    "    'sample_size':ParameterInteger(name='sample_size', default_value=10),\n",
    "    'mean_wQL_score_threshold':ParameterFloat(name='mean_wQL_score_threshold', default_value=0.2),\n",
    "    'model_package_group_name':ParameterString(name='model_package_group_name', default_value=model_package_group_name),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f98b2-3073-4781-b4b1-4d58b95c8502",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "\n",
    "Now define the pipeline by combinining all step together. There are two additional steps in the pipeline.\n",
    "\n",
    "**Condition step**  \n",
    "The condition step checks the model performance score calculated in the training step and conditionally creates a model and registers it in the model registry, or stops and fails the pipeline execution.\n",
    "\n",
    "**Fail step**  \n",
    "A Pipelines [FailStep](https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.fail_step.FailStep) stops the pipeline execution if the model performance metric doesn't meet the specified threshold.\n",
    "\n",
    "You need to pass only the last step to Pipeline constructor. The SDK automatically builds a pipeline DAG based on data dependencies between steps. Refer to the [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-overview.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa370884-86d3-4bbc-9a0a-c5347c4ef044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts_pipeline.preprocess import preprocess\n",
    "from gluonts_pipeline.train_step import train\n",
    "from gluonts_pipeline.register import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5255039-96f6-4438-877e-acdd61350737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data step\n",
    "step_preprocess = step(\n",
    "    preprocess, \n",
    "    instance_type=pipeline_parameters['processing_instance_type'],\n",
    "    keep_alive_period_in_seconds=1800,\n",
    ")(\n",
    "    input_data_s3_path=pipeline_parameters['input_data_s3_path'],\n",
    "    output_s3_prefix=pipeline_parameters['s3_output_data_prefix'],\n",
    "    freq=pipeline_parameters['freq'],\n",
    "    prediction_length=pipeline_parameters['prediction_length'],\n",
    "    data_start=pipeline_parameters['data_start'],\n",
    "    data_end=pipeline_parameters['data_end'],\n",
    "    backtest_windows=pipeline_parameters['backtest_windows'],\n",
    "    sample_size=pipeline_parameters['sample_size'],  \n",
    "    pipeline_run_id=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    ")\n",
    "\n",
    "# training step with PyTorch estimator\n",
    "step_train = TrainingStep(\n",
    "    name='train',\n",
    "    step_args=PyTorch(\n",
    "        entry_point='train.py',\n",
    "        source_dir='gluonts_pipeline',\n",
    "        framework_version=dlc_framework_version,  \n",
    "        py_version=python_version,\n",
    "        hyperparameters=hyperparameters,\n",
    "        role=sm_role,\n",
    "        instance_count=1,\n",
    "        instance_type=pipeline_parameters['training_instance_type'],\n",
    "        output_path=pipeline_parameters['s3_output_train_prefix'],\n",
    "        base_job_name=\"gluonts-pipeline-training\",\n",
    "        metric_definitions=metric_definitions,\n",
    "        sagemaker_session=PipelineSession(),\n",
    "    ).fit({'train':step_preprocess['train_data'], 'test':step_preprocess['test_data']}),\n",
    "    # cache_config=CacheConfig(enable_caching=True, expire_after=\"P30d\"),\n",
    ")\n",
    "\n",
    "# This code if you use the training script with @step decorator\n",
    "# step_train = step(\n",
    "#     train,\n",
    "#     instance_type=pipeline_parameters['training_instance_type'],\n",
    "#     keep_alive_period_in_seconds=1800,\n",
    "# )(\n",
    "#     train_data_s3_path=step_preprocess['train_data'],\n",
    "#     test_data_s3_path=step_preprocess['test_data'],\n",
    "#     output_s3_prefix=pipeline_parameters['s3_output_train_prefix'],\n",
    "#     hyperparameters=hyperparameters,\n",
    "# )\n",
    "\n",
    "# register model step\n",
    "step_register = step(\n",
    "    register, \n",
    "    keep_alive_period_in_seconds=1800,\n",
    ")(\n",
    "    training_job_name=step_train.properties.TrainingJobName,\n",
    "    model_package_group_name=pipeline_parameters['model_package_group_name'],\n",
    "    pipeline_run_id=step_preprocess['pipeline_run_id'],\n",
    ")\n",
    "\n",
    "# fail the pipeline execution step\n",
    "step_fail = FailStep(\n",
    "    name='fail',\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\"Execution failed due to mean_wQL > \", pipeline_parameters['mean_wQL_score_threshold']]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# check if the test score acceptable\n",
    "step_condition = ConditionStep(\n",
    "    name='check-mean-wQL',\n",
    "    conditions=[\n",
    "        ConditionLessThanOrEqualTo(\n",
    "            left=step_train.properties.FinalMetricDataList['test_mean_wQuantileLoss'].Value,\n",
    "            right=pipeline_parameters['mean_wQL_score_threshold']\n",
    "    )],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[step_fail],\n",
    ")\n",
    "\n",
    "# Create a pipeline object\n",
    "pipeline = Pipeline(\n",
    "    name=f\"{pipeline_name}\",\n",
    "    parameters=[v for v in pipeline_parameters.values()],\n",
    "    steps=[step_condition],\n",
    "    pipeline_definition_config=PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298ebf4-ff0d-4799-b48a-c17d1ba92531",
   "metadata": {},
   "source": [
    "#### Upsert the pipeline\n",
    "\n",
    "If a pipeline with the same name already exits, SageMaker will update it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0016f43-224d-4ea1-837f-18811379dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert operation serialize the function code, arguments, and other artefacts to S3 where it can be accessed during pipeline's runtime\n",
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5df02-e5b6-47e9-968d-1db83f467d50",
   "metadata": {},
   "source": [
    "To see the created pipeline in the Studio UI, click on the link constructed by the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2da8d3-55e6-49ba-b815-141208ae746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Show the pipeline link\n",
    "display(\n",
    "    HTML('<b>See <a target=\"top\" href=\"https://studio-{}.studio.{}.sagemaker.aws/pipelines/{}/graph\">the pipeline</a> in the Studio UI</b>'.format(\n",
    "            domain_id, region, pipeline_name))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf09b6-33b6-4190-8e47-6b806a9b841d",
   "metadata": {},
   "source": [
    "### Execute the pipeline\n",
    "\n",
    "A pipeline execution takes about 20 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace22352-f5f9-4af1-acb6-85ddec0b5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this starts a pipeline execution\n",
    "pipeline_execution = pipeline.start()\n",
    "pipeline_execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246110a-ad14-4c00-936e-25ab24bbefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you would like to wait in the notebook until this execution completes\n",
    "# pipeline_execution.wait() \n",
    "pipeline_execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08690b93-30f6-48cf-b0b2-703cb48e47e0",
   "metadata": {},
   "source": [
    "You can see the pipeline execution in the Studio UI by clicking on the link constructed by the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f6a8dc-9ea7-49a8-a970-bc3f564ec8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the pipeline execution link\n",
    "display(\n",
    "    HTML('<b>See <a target=\"top\" href=\"https://studio-{}.studio.{}.sagemaker.aws/pipelines/{}/executions/{}/graph\">the pipeline execution</a> in the Studio UI</b>'.format(\n",
    "            domain_id, region, pipeline_name, pipeline_execution.describe()['PipelineExecutionArn'].split('/')[-1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dddb95f-a66f-4be5-92a9-6dd521e82d78",
   "metadata": {},
   "source": [
    "### Explore pipeline execution\n",
    "\n",
    "After the pipeline execution completed, you have a trained model which is registered as a new model version in the specified model package group in the SageMaker Model Registry. You can also explore calculated model metrics and get any details on the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51ee61-13e5-43ee-ad1c-8867167733f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the execution completed\n",
    "pipeline_execution.wait()\n",
    "assert pipeline_execution.describe()['PipelineExecutionStatus'] == 'Succeeded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c119ff6-993f-4cb7-a316-107c3a61fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_id = pipeline_execution.arn.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576b06c-f6d1-4efb-8cc2-b4e807f5e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all steps with StepStatus\n",
    "pipeline_execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a661c8-1bf4-4c6b-85c3-e3cc16392355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d29656-6842-4543-a6cb-daceaa39af9d",
   "metadata": {},
   "source": [
    "### Explore training metrics\n",
    "\n",
    "You can access metrics stored in the training job execution metadata or download the metric files from S3. SageMaker automatically captures and saves metrics emitted by the training job via the log stream by looking for metrics defined in `metric_definitions` regex. You passed the `metric_definition` parameter to the training estimator during creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489507e-834a-4e48-9051-62e456ffb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training job name from the pipeline step properties\n",
    "train_step = [s for s in pipeline_execution.list_steps() if s['StepName'] == 'train'][0]\n",
    "training_job_name = train_step['Metadata']['TrainingJob']['Arn'].split('/')[-1]\n",
    "\n",
    "# Attach an estimator object to the job\n",
    "estimator = Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d0fc7-b417-4255-8547-17d7ffce6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display training job metrics\n",
    "# these metrics were automatically captured and saved by SageMaker based on metric_definitions\n",
    "estimator.training_job_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c8076-2620-4e25-b041-a5ec74a1b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all job properties including S3 output prefix where training artefacts stored\n",
    "job_description = boto3.client('sagemaker').describe_training_job(TrainingJobName=training_job_name)\n",
    "s3_output_prefix = job_description['OutputDataConfig']['S3OutputPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f1216-68c3-4ef7-9eb1-b57d2ee63ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display train artefacts uploaded to S3 by the training job\n",
    "!aws s3 ls {s3_output_prefix}/{training_job_name} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2341d97-4837-42e3-b10e-8caa56ac5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and extract model metrics to the local volume\n",
    "!aws s3 cp {s3_output_prefix}/{training_job_name}/output/output.tar.gz .\n",
    "!tar -xvf ./output.tar.gz -C output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c6705-4b95-423e-b7de-6d25a98ac534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display aggregated test metrics\n",
    "with open('output/agg_metrics.json', 'r') as f:\n",
    "    agg_metrics = json.load(f)\n",
    "\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355a037-c0fb-4e6d-aaa9-4b9a6c934357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display item-level metrics\n",
    "item_metrics = pd.read_csv(\"output/item_metrics.csv.gz\", compression=\"gzip\")\n",
    "visualize_item_metric(item_metrics, 'sMAPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f036cf-1a6f-4ec1-b116-d411a7fb637e",
   "metadata": {},
   "source": [
    "### Deploy the model to a real-time endpoint\n",
    "\n",
    "Now having a model version registered in the model registry, you can deploy this version as a SageMaker endpoint and run real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c81e6-dec1-4338-93cd-8ab5842b3f5a",
   "metadata": {},
   "source": [
    "#### Explore model registry\n",
    "\n",
    "First take a look at the registered model version in the model package group. Open the link constructed by the following code cell and explore model version details. Note that you have end-to-end data lineage for the registered model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633cdda5-f0aa-435b-bfcd-740fb86fa37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you choose a specific model package to take the model from\n",
    "# model_package_group_name = <model package group name>\n",
    "model_package_group_name = pipeline_parameters['model_package_group_name'].default_value\n",
    "\n",
    "# get the latest model version in the model package group\n",
    "sm_model_package = boto3.client('sagemaker').list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    ")['ModelPackageSummaryList'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880114b6-e46d-4626-a4c7-0cebfc9f5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Show the model version link\n",
    "display(\n",
    "    HTML('<b>See <a target=\"top\" href=\"https://studio-{}.studio.{}.sagemaker.aws/models/registered-models/{}/versions/version-{}/lineage\">the model version lineage</a> in the Studio UI</b>'.format(\n",
    "            domain_id, region, pipeline_parameters['model_package_group_name'].default_value, sm_model_package['ModelPackageVersion']))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd8b18-ed7d-4cda-89e0-875e11c0c029",
   "metadata": {},
   "source": [
    "#### Deploy the model\n",
    "\n",
    "You can deploy a trained model using the SageMaker Model Registry as the model metadata source. The model registry contains all information needed to deploy and to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc38ec-a495-4466-8447-03bbfbafef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb949c-43e8-4df4-8907-7ffbe070bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each model version has its own ARN\n",
    "model_package_arn = sm_model_package['ModelPackageArn']\n",
    "model_package_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738c712-829f-4b47-95cb-dd1ec8288dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model data from the model registry\n",
    "sm_model_package_data = boto3.client('sagemaker').describe_model_package(\n",
    "    ModelPackageName=model_package_arn\n",
    ")\n",
    "\n",
    "# get the associated pipeline_run_id from the model metadata\n",
    "pipeline_execution_id = sm_model_package_data['CustomerMetadataProperties'].get('pipeline_run_id')\n",
    "if not pipeline_execution_id:\n",
    "    pipeline_execution_id = sm_model_package_data['InferenceSpecification']['Containers'][0]['ModelDataUrl'].split('-')[-2]\n",
    "\n",
    "print(f\"Using version {sm_model_package_data['ModelPackageVersion']} of {sm_model_package_data['ModelPackageGroupName']}\")\n",
    "print(f'The model was registered by the pipeline execution {pipeline_execution_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c473a3-fd68-4ac1-b8a2-396aa907fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a meanful endpoint name\n",
    "tft_endpoint_name = f\"model-endpoint-{sm_model_package_data['ModelPackageGroupName']}-v{sm_model_package_data['ModelPackageVersion']}\"\n",
    "tft_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e4d45-c259-4e99-9930-6f4a865a6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the endpoint config if exists\n",
    "try:\n",
    "    sm = boto3.client('sagemaker')\n",
    "    sm.describe_endpoint_config(EndpointConfigName=tft_endpoint_name)\n",
    "    sm.delete_endpoint_config(EndpointConfigName=tft_endpoint_name)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c535ca-f8c4-4128-89af-09bf55d732e0",
   "metadata": {},
   "source": [
    "The following code implements a custom predictor class derived from the SageMaker Python SDK [`Predictor`](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor). You can use the custom predictor to perform any required data pre- and postprocessing on the client side. The custom predictor also takes care of request serialization and response deserialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1e8a3-6f61-4a39-9ba4-07153267b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "from typing import List, Dict, Tuple, Union\n",
    "\n",
    "class GluontsTFTPredictor(sagemaker.predictor.Predictor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            # serializer=JSONSerializer(),\n",
    "            serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        list_dataset:ListDataset,\n",
    "        prediction_start:pd.Timestamp,\n",
    "        context_length:int=4*prediction_length,\n",
    "        num_samples:int=20, # not used in TFT predictor\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Input: dataset, prediction_start date, context_length\n",
    "        The function prepares the required part of the dataset and serializes it as json str\n",
    "        Output: a list of QuantileForecast objects\n",
    "        \"\"\"\n",
    "\n",
    "        freq = list_dataset[0][FieldName.START].freq\n",
    "        dataset_start = list_dataset[0][FieldName.START]\n",
    "        \n",
    "        # calculate the start of prediction dataset based on required context\n",
    "        prediction_input_start = prediction_start - context_length*freq\n",
    "        \n",
    "        # calculate lower und upper array indices for the required part of the dataset\n",
    "        l = len(pd.date_range(start=dataset_start.to_timestamp(), end=prediction_input_start, freq=freq))\n",
    "        u = len(pd.date_range(start=dataset_start.to_timestamp(), end=prediction_start, freq=freq))\n",
    "\n",
    "        return self.__decode_response(\n",
    "            super(GluontsTFTPredictor, self).predict(self.__encode_request(\n",
    "                list_dataset, prediction_input_start, l, u, num_samples\n",
    "            )))\n",
    "        \n",
    "    def __encode_request(self, dataset, start_date, start_idx, end_idx, num_samples):\n",
    "        inputs = {\n",
    "            \"inputs\":[\n",
    "                {\n",
    "                    FieldName.ITEM_ID: i[FieldName.ITEM_ID],\n",
    "                    FieldName.TARGET: i[FieldName.TARGET][start_idx:end_idx].tolist(),\n",
    "                    FieldName.START: start_date.isoformat(),\n",
    "                }\n",
    "                for i in dataset\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        parameters = {\n",
    "            \"parameters\": {\n",
    "                \"freq\": dataset[0][FieldName.START].freq.freqstr,\n",
    "                \"num_samples\": num_samples\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return json.dumps({**inputs, **parameters}).encode('utf-8')\n",
    "\n",
    "    def __decode_response(self, response):\n",
    "        return json.loads(response.decode('utf-8'), object_hook=quantile_forecast_decoder)\n",
    "\n",
    "\n",
    "def quantile_forecast_decoder(obj):\n",
    "    if \"__type__\" in obj and obj[\"__type__\"] == \"QuantileForecast\":\n",
    "        return QuantileForecast(\n",
    "            forecast_arrays=np.array(obj[\"forecast_arrays\"]),\n",
    "            start_date=pd.Period(obj[\"start_date\"], obj['freq']),\n",
    "            forecast_keys=obj[\"forecast_keys\"],\n",
    "            item_id=obj[\"item_id\"],\n",
    "            info=obj[\"info\"],            \n",
    "        )\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3df30-5418-445a-8ec7-adadd1b21ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch model object\n",
    "model = PyTorchModel(\n",
    "    role=sm_role,\n",
    "    model_data=sm_model_package_data['InferenceSpecification']['Containers'][0]['ModelDataUrl'],\n",
    "    framework_version=sm_model_package_data['InferenceSpecification']['Containers'][0]['FrameworkVersion'],\n",
    "    py_version=python_version,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='gluonts_pipeline',\n",
    "    predictor_cls=GluontsTFTPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008b520-603d-4abe-aa7d-6b7f9df07614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supported real-time inference instances\n",
    "ep_instances = sm_model_package_data['InferenceSpecification']['SupportedRealtimeInferenceInstanceTypes']\n",
    "ep_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8a783-ca94-4cf9-93e1-ac80ced9c5a9",
   "metadata": {},
   "source": [
    "Based on the account service quotas get the best available instances type for the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad795b1b-e50a-404d-b015-f6fce9dfb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_instance_map = {\n",
    "    'ml.g5.2xlarge':'L-9614C779',\n",
    "    'ml.g5.xlarge':'L-1928E07B',\n",
    "    'ml.m5.2xlarge':'L-C88C8F13',\n",
    "    'ml.m5.xlarge':'L-2F737F8D',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ecdfa-0a9b-4fd8-9d28-e0f7c45ad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_instance = get_best_instance({k:v for k,v in ep_instance_map.items() if k in ep_instances})\n",
    "print(f'Use {ep_instance} for the endpoint based on the avaliable quotas and supported instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498cfda7-e7de-4aa3-9107-d4eee5890647",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd8ee7-bcd8-4428-b95b-054ccefb77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to an endpoint\n",
    "tft_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=ep_instance,\n",
    "    endpoint_name=tft_endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea77f0-113e-4981-a615-6cf11b832799",
   "metadata": {},
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c72e28-1143-4aae-9bd6-52a49d7f06f0",
   "metadata": {},
   "source": [
    "### Make predictions and visualize\n",
    "\n",
    "Now having a real-time inference endpoint, you can send datasets for predictions. This section creates an interactive visualization of forecasts generated by the trained model.\n",
    "\n",
    "Use the test dataset which was created by the pipeline's preprocessing job. This ensures that you use the same subset of the time series that was used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fa905-d192-4137-9277-305ce6068dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset from the preprocessing step\n",
    "!aws s3 cp {s3_output_data_prefix}/{pipeline_execution_id}/test/test.jsonl.gz ./data\n",
    "\n",
    "# load the dataset for predictions\n",
    "test_ds = ListDataset(JsonLinesFile(Path('./data/test.jsonl.gz')), freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05134458-a684-414a-9b07-b9093656a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Test dataset contains {len(test_ds)} time series\n",
    "Time series: {[i[FieldName.ITEM_ID] for i in test_ds]}\n",
    "Dataset start is {test_ds[0][FieldName.START]}\n",
    "Each time series contains {len(test_ds[0][FieldName.TARGET])} data points\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81055df2-794b-4fb6-9394-bc152e2c1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's also possible to create a local predictor with the trained model\n",
    "# !aws s3 cp {sm_model_package_data['InferenceSpecification']['Containers'][0]['ModelDataUrl']} .\n",
    "# !tar -xvf ./model.tar.gz -C output/model/\n",
    "# tft_predictor_local = Predictor.deserialize(Path(\"./output/model\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c759d92-e194-45db-a492-1b2b6cd3ba2a",
   "metadata": {},
   "source": [
    "Make predictions using the real-time endpoint and evaluate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184806af-b9b0-4b68-8560-1d77990630e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a data four weeks before the end of the dataset for the prediction start\n",
    "prediction_start = end_dataset_date - 4*prediction_length*test_ds[0][FieldName.START].freq\n",
    "# call the endpoint to generate forecasts\n",
    "forecasts = tft_predictor.predict(test_ds, prediction_start, 4*prediction_length)\n",
    "\n",
    "# calculate metrics for the forecasts\n",
    "evaluator = Evaluator(quantiles=(np.arange(10) / 10.0)[1:])\n",
    "agg_metrics, item_metrics = evaluator(\n",
    "    [to_pandas(i) for i in test_ds], \n",
    "    forecasts,\n",
    "    num_series=len(test_ds),\n",
    ")\n",
    "\n",
    "# show metrics\n",
    "agg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fb5fe-1462-4951-b5fd-67a79e0fc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_item_metric(item_metrics, 'sMAPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7965bd5-a8c2-4c0b-baad-d8f7fd2dd489",
   "metadata": {},
   "source": [
    "#### Interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3b884-fe50-47f0-ad5d-054c9feda8fd",
   "metadata": {},
   "source": [
    "Visualize model predictions using the following interactive control. You can change the following parameters:\n",
    "\n",
    "- `Time series ids`: ids of the time series in the test dataset. You can select multiple time series to predict and to plot\n",
    "- `Predict from`: start of the prediction interval  \n",
    "- `Context length`: how many `prediction_length` of data points are sent to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d837b1-1464-4cae-acdc-5711dc7803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {\"description_width\": \"initial\"}\n",
    "ts_id_list = [i[FieldName.ITEM_ID] for i in test_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e696dab-6ed6-45f9-a6f3-b9aff14419b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    ts_ids=SelectMultiple(options=ts_id_list, value=[ts_id_list[0]], rows=5, style=style, description='Time series ids:'),    \n",
    "    prediction_start=DatePicker(value=data_end, style=style, description='Predict from:'),\n",
    "    context_length=IntSlider(min=1, max=10, value=4, style=style, description='Context length:'),\n",
    "    # num_samples=IntSlider(min=1, max=100, value=20, style=style, description='Number of samples:'),\n",
    "    continuous_update=False,\n",
    ")\n",
    "def plot_interact(ts_ids, prediction_start, context_length):\n",
    "\n",
    "    def _to_pandas_dict(list_ds, start, end) -> Dict[str, pd.Series]:\n",
    "        return {i[FieldName.ITEM_ID]:to_pandas(i)[start:end] for i in list_ds}\n",
    "\n",
    "    freq = test_ds[0][FieldName.START].freq\n",
    "    prediction_start = pd.Timestamp(prediction_start)\n",
    "    prediction_ds = [i for i in test_ds if i[FieldName.ITEM_ID] in ts_ids]\n",
    "    historical_series = _to_pandas_dict(prediction_ds, prediction_start - context_length*prediction_length*freq, prediction_start)\n",
    "    label_series = _to_pandas_dict(prediction_ds, prediction_start, prediction_start + prediction_length*freq)\n",
    "\n",
    "    # call the endpoint to generate forecasts\n",
    "    forecasts = tft_predictor.predict(prediction_ds, prediction_start, context_length*prediction_length)\n",
    "    \n",
    "    figs = []\n",
    "    c_interval = float(forecasts[0].forecast_keys[-1])\n",
    "    for i, f in tqdm.tqdm(enumerate(forecasts), total=len(forecasts), desc='Creating plots'):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15,4))\n",
    "\n",
    "        ax.set_title(f'Time series: {f.item_id}')\n",
    "        ax.plot(historical_series[f.item_id].to_timestamp(), color=colors[i % len(colors)], linewidth=3)\n",
    "        ax.plot(label_series[f.item_id].to_timestamp())\n",
    "        f.plot(intervals=(c_interval,), name=f'{f.item_id} forecast', show_label=True)\n",
    "\n",
    "        plt.legend(['Historical', 'Ground truth', 'Predicted median', f'{c_interval*100:.0f}% confidence interval'], loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        figs.append(fig)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4894e6-d497-4a12-a8a4-5a42bb05fc3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132e335-3e6f-4e6a-b28d-3c00ebce54a4",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "GluonTS offers an advanced framework to create, train, and evaluate your own models. Refer to the GluonTS tutorial [Create your own model](https://ts.gluon.ai/stable/tutorials/forecasting/extended_tutorial.html#Create-your-own-model) for detailed documentation.\n",
    "\n",
    "If you would like to run GluonTS training and predictions in a custom container, for example using SageMaker training or batch transform jobs, refer to this [sample Dockerfiles for GluonTS](https://github.com/awslabs/gluonts/tree/dev/examples/dockerfiles) GitHub repository.\n",
    "\n",
    "You can find another example of productizaiton of GluonTS training in GitHub repository [Deep Demand Forecasting with Amazon SageMaker](https://github.com/awslabs/sagemaker-deep-demand-forecast). This example uses processing and training job with MXNet LSTNet estimator to implement a training pipeline.\n",
    "\n",
    "For management of ML experiments, metrics, models, and artifacts you can use [SageMaker managed MLflow](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html). With MLflow you track, organize, view, analyze, and compare iterative ML experimentation to gain comparative insights and register and deploy your best performing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5f0cd-187f-4394-a8bb-e543417f2f6f",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "If you don't need the deployed endpoint anymore, delete it to avoid incuring unnecessary costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d442e7-d366-4375-a43c-7147379ab1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the endpoint and the model\n",
    "tft_predictor.delete_endpoint()\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a370ccd-fe90-4409-a302-839aa1d9aea6",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
